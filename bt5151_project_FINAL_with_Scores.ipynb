{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca8142d-565d-4804-b722-1c93cbf9e5dd",
   "metadata": {},
   "source": [
    "## I. Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac02888e-0da0-4459-aaf5-f8a727f2444f",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "After loading the D1 and D2 dataset, it can be seen that D1 dataset and D2 Dataset has the following columns:\n",
    "\n",
    "- **D1 Dataset**:\n",
    "    - training dataset, 5 columns:\n",
    "        - id \n",
    "        - keyword\n",
    "        - location\n",
    "        - text\n",
    "        - target\n",
    "       \n",
    "    - test dataset, 4 columns without target variable:\n",
    "        - id \n",
    "        - keyword\n",
    "        - location\n",
    "        - text  \n",
    "     \n",
    "- **D2 Dataset**:\n",
    "    - 4 columns: \n",
    "        - textID\n",
    "        - text\n",
    "        - selected_text \n",
    "        - sentiment (target column)\n",
    "\n",
    "We will do preprocessing of the both the datasets such as imputing based on the null values the two datasets have in the following section. D1 train dataset has 7613 records and D1 test dataset has 3263 records giving a total of 10786 records for D1 dataset. D2 dataset has 27481 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77f39b50-3548-4264-aad8-9963d6b923ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id keyword location                                               text  \\\n",
      "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
      "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
      "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
      "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
      "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
      "\n",
      "   target  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1   \n",
      "\n",
      "       textID                                               text  \\\n",
      "0  cb774db0d1                I`d have responded, if I were going   \n",
      "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
      "2  088c60f138                          my boss is bullying me...   \n",
      "3  9642c003ef                     what interview! leave me alone   \n",
      "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
      "\n",
      "                         selected_text sentiment  \n",
      "0  I`d have responded, if I were going   neutral  \n",
      "1                             Sooo SAD  negative  \n",
      "2                          bullying me  negative  \n",
      "3                       leave me alone  negative  \n",
      "4                        Sons of ****,  negative   \n",
      "\n",
      "Shape of D1 train dataset is (7613, 5)\n",
      "Shape of D1 test dataset is (3263, 4)\n",
      "Shape of D1 dataset is (10876, 5)\n",
      "Shape of D2 dataset is (27481, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "df_d1_train = pd.read_csv('train.csv')\n",
    "df_d1_test = pd.read_csv('test.csv')\n",
    "df_d2 = pd.read_csv('Tweets.csv')\n",
    "df_d1 = pd.concat([df_d1_train, df_d1_test])\n",
    "\n",
    "shape_d1_train = df_d1_train.shape\n",
    "shape_d1_test = df_d1_test.shape\n",
    "shape_d1 = df_d1.shape\n",
    "shape_d2 = df_d2.shape\n",
    "\n",
    "print(df_d1_train.head(), '\\n')\n",
    "print(df_d2.head(), '\\n')\n",
    "print(f'Shape of D1 train dataset is {shape_d1_train}')\n",
    "print(f'Shape of D1 test dataset is {shape_d1_test}')\n",
    "print(f'Shape of D1 dataset is {shape_d1}')\n",
    "print(f'Shape of D2 dataset is {shape_d2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e62ec6-8743-4e81-a081-5edaf3062775",
   "metadata": {},
   "source": [
    "## I. Dataset Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7464cf53-3a78-4212-aa8c-484a69010335",
   "metadata": {},
   "source": [
    "### Preprocessing of D1 Data\n",
    "\n",
    "We will just be using the text as an input variable and the disaster variable as the output variable for our models using D1 dataset. Therefore, we can drop the id, keyword and location columns from both the train and test datasets of D1. The train and test dataset is then checked for null values. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4c2ecb-bc2f-4302-a2c2-d3f4d907e5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d1_train = df_d1_train.drop(['id', 'keyword', 'location'], axis=1)\n",
    "df_d1_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e786820-a108-4270-896e-7427019f4f74",
   "metadata": {},
   "source": [
    "There are no null values present in d1 train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75ac92c2-3f60-4352-81c5-685537b1d50c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d1_test = df_d1_test.drop(['id', 'keyword', 'location'], axis=1)\n",
    "df_d1_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab72a9ea-2250-4861-90b5-37aa9f38cf21",
   "metadata": {},
   "source": [
    "Since the test dataset does not have the target column, only text column is present and there are no null values.\n",
    "\n",
    "Since there are no null values in both test and train datasets for D1, we do no need to do any imputing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d618f3-59dc-4be1-b701-7930ec07b67b",
   "metadata": {},
   "source": [
    "### Preprocessing of D2 Data\n",
    "\n",
    "We will conduct the same analysis for D2 dataset. We will only need the test column and sentiments(target) column for our models using D2 dataset. Therfore, we drop the rest of the columns and check for null values for these two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0467465-a6a1-4586-ab09-b55fee296ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         1\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d2 = df_d2.drop(['textID', 'selected_text'], axis=1)\n",
    "df_d2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d783ea-7b3f-4ac5-b366-de1283cdf77b",
   "metadata": {},
   "source": [
    "Since there is only 1 record with null value under text column. We will drop this null record from the dataset for our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6473da25-2564-4ada-84db-916709a0309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27480, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d2 = df_d2.dropna()\n",
    "df_d2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814fb15d-cddd-4556-96f1-85389a0a2497",
   "metadata": {},
   "source": [
    "### Preprocessing and Tokenizing the Text variable for both D1 and D2 dataset\n",
    "\n",
    "We will combine the D1 and D2 dataset for the text columns to tokenize the text input records so that they fall under the same vocabulary when tokeninzing them. Before tokeninz them we used this TextHero package to preprocess the text input for the following:\n",
    "\n",
    "* Lowercase all text.\n",
    "* Remove all accents from strings.\n",
    "* Remove all stop words.\n",
    "* Remove all blocks of digits.\n",
    "* Remove all string.punctuation (!\"#$%&'()*+,-./:;<=>?@[]^_`{|}~).\n",
    "* Replace unassigned values with empty spaces.\n",
    "* Remove all white space between words\n",
    "\n",
    "An example of the raw text and cleaned text are shown in the two tables below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d33ade-7e7b-4714-ac3b-ccb67284a859",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = pd.concat([df_d1['text'], df_d2['text']], ignore_index = True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55446734-df11-4156-995c-3dda0f410c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Our Deeds are the Reason of this #earthquake M...\n",
      "1               Forest fire near La Ronge Sask. Canada\n",
      "2    All residents asked to 'shelter in place' are ...\n",
      "3    13,000 people receive #wildfires evacuation or...\n",
      "4    Just got sent this photo from Ruby #Alaska as ...\n",
      "5    #RockyFire Update => California Hwy. 20 closed...\n",
      "6    #flood #disaster Heavy rain causes flash flood...\n",
      "7    I'm on top of the hill and I can see a fire in...\n",
      "8    There's an emergency evacuation happening now ...\n",
      "9    I'm afraid that the tornado is coming to our a...\n",
      "Name: text, dtype: object \n",
      "\n",
      "0         deeds reason earthquake may allah forgive us\n",
      "1                forest fire near la ronge sask canada\n",
      "2    residents asked shelter place notified officer...\n",
      "3    people receive wildfires evacuation orders cal...\n",
      "4    got sent photo ruby alaska smoke wildfires pou...\n",
      "5    rockyfire update california hwy closed directi...\n",
      "6    flood disaster heavy rain causes flash floodin...\n",
      "7                              top hill see fire woods\n",
      "8    emergency evacuation happening building across...\n",
      "9                           afraid tornado coming area\n",
      "Name: clean_text, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import texthero as hero\n",
    "\n",
    "df_corpus['clean_text'] = hero.clean(df_corpus['text'])\n",
    "df_corpus = df_corpus.drop('index', axis=1)\n",
    "print(df_corpus['text'].head(10),'\\n')\n",
    "print(df_corpus['clean_text'].head(10),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebd8d0c3-9c7c-4686-b324-9afbb92b8086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38356,)\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seqlen = df_corpus[\"clean_text\"].apply(lambda x: len(x.split()))\n",
    "print(seqlen.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58882c3d-95ee-496d-a217-c0f8d792e5c5",
   "metadata": {},
   "source": [
    "Once the text is cleaned, we used the DistilBertTokenizer which is a pre-trained NLP model tokenizer to tokenize the text inputs. After tokenizing, we need to pad the tokenized texts to make the dimensions the same for all tokenized texts. We would then use the pre-trained DistilBertModel to extract features of dimensions 768 using these padded tokens as input to the model. \n",
    "\n",
    "Since, the model took very long to extract the features(sentence vectors) for the text inputs from the combined D1 and D2 datasets, the extracted sentence vectors were saved as a .csv file for future loading of the vectors instead of running the model to extract the features again. These extracted sentence vectors of dimension 768 will be used as the input for the next few sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e465363-6151-4281-811f-25c511030fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38356, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# Load pre-trained model (weights)\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "tokenized = df_corpus['clean_text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True, max_length=512, truncation=True)))\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "attention_mask.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7075cfa8-ebdb-4d38-92f9-541df34b5163",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only ran this code once to extract the sentecnce vector using BERT model and saved\n",
    "## it as a .csv file for future loading of the vector instead of runnign the code again\n",
    "## as it takes long and consumes alot of memory to extract the sentence vectors from\n",
    "## BERT Model - saved vectors - features.csv\n",
    "\n",
    "\n",
    "from numpy import savetxt\n",
    "\n",
    "feature_list = []\n",
    "with torch.no_grad():\n",
    "    for batch_idx in range(0,padded.shape[0],10):\n",
    "        #BERT check 10 sample each time.\n",
    "        input_ids = torch.tensor(padded[batch_idx:batch_idx+10])  \n",
    "        used_attention_mask = torch.tensor(attention_mask[batch_idx:batch_idx+10])\n",
    "        last_hidden_states = model(input_ids, attention_mask=used_attention_mask)\n",
    "        #Get the embeddings for the [CLS] tag (position is 0)\n",
    "        features = last_hidden_states[0][:,0,:]\n",
    "        feature_list.append(features)\n",
    "\n",
    "features = np.vstack(features_list)\n",
    "\n",
    "# save features array as a .csv file for loading later\n",
    "savetxt('features.csv', features, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3ad1ec-b1e2-4c60-89b5-ec97b3994897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38356, 768)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Load the saved sentence vectors for both D1 and D2 text dataset\n",
    "from numpy import loadtxt\n",
    "# load array\n",
    "features = loadtxt('features.csv', delimiter=',')\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125a985-00d4-47c1-b267-cc0571eb7c69",
   "metadata": {},
   "source": [
    "Once the sentence vectors has been extracted using the Bert Model for the combined D1 and D2 datasets, the data is again split back to D1(both train and test dataset) and D2.The labels for the 3 class sentiments target variable were also ordinally encoded.\n",
    "\n",
    "The datasets for D1 train dataset and D2 dataset were train-test-split with a 80%/20% ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5041dadb-4054-462f-b82f-c701a2d14cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7613, 768)\n",
      "(3263, 768)\n",
      "(27480, 768)\n"
     ]
    }
   ],
   "source": [
    "## split back into D1 and D2 dataset\n",
    "\n",
    "d1_train_features = features[0:shape_d1_train[0]]\n",
    "d1_test_features = features[shape_d1_train[0]:shape_d1_train[0] + shape_d1_test[0]]\n",
    "d2_features = features[shape_d1_train[0] + shape_d1_test[0]:]\n",
    "\n",
    "print(d1_train_features.shape)\n",
    "print(d1_test_features.shape)\n",
    "print(d2_features.shape)\n",
    "\n",
    "def convert_2darray_to_df(arrays_2d):\n",
    "    list_of_arrays = [row for row in arrays_2d]\n",
    "    \n",
    "    return list_of_arrays\n",
    "\n",
    "\n",
    "df_d1_train['sentence_embeddings'] = convert_2darray_to_df(d1_train_features)\n",
    "df_d1_test['sentence_embeddings'] = convert_2darray_to_df(d1_test_features)\n",
    "df_d2['sentence_embeddings'] = convert_2darray_to_df(d2_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca9020f2-cba4-4a05-9c04-5f2082e14f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>sentence_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.10347555577754974, 0.0949205756187439, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4164022207260132, 0.19298885762691498, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.2418411374092102, -0.1157110333442688, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.12487819045782089, 0.030626526102423668, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0019691395573318005, -0.14926283061504364,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.2051445096731186, 0.09096449613571167, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.23618453741073608, -0.10245174914598465, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.35735654830932617, 0.006355086341500282, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4586879014968872, -0.25744855403900146, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.19707342982292175, -0.10754090547561646, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                    sentence_embeddings  \n",
       "0     [-0.10347555577754974, 0.0949205756187439, -0....  \n",
       "1     [-0.4164022207260132, 0.19298885762691498, -0....  \n",
       "2     [-0.2418411374092102, -0.1157110333442688, 0.1...  \n",
       "3     [-0.12487819045782089, 0.030626526102423668, -...  \n",
       "4     [-0.0019691395573318005, -0.14926283061504364,...  \n",
       "...                                                 ...  \n",
       "7608  [-0.2051445096731186, 0.09096449613571167, -0....  \n",
       "7609  [-0.23618453741073608, -0.10245174914598465, -...  \n",
       "7610  [-0.35735654830932617, 0.006355086341500282, 0...  \n",
       "7611  [-0.4586879014968872, -0.25744855403900146, -0...  \n",
       "7612  [-0.19707342982292175, -0.10754090547561646, -...  \n",
       "\n",
       "[7613 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-processed dataset of D1 train\n",
    "df_d1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7310d499-7b65-4e60-9c08-3ceccb1862b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentence_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "      <td>[-0.25721344351768494, -0.15935777127742767, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "      <td>[0.02665054053068161, -0.25792196393013, 0.041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "      <td>[-0.21820902824401855, 0.044809360057115555, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "      <td>[-0.2617347240447998, 0.05129344016313553, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "      <td>[-0.4326396882534027, -0.2646219730377197, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...</td>\n",
       "      <td>[-0.1371319741010666, -0.19958768784999847, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>Storm in RI worse than last hurricane. My city...</td>\n",
       "      <td>[-0.0810704380273819, -0.11629102379083633, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>Green Line derailment in Chicago http://t.co/U...</td>\n",
       "      <td>[-0.18644750118255615, -0.1975667029619217, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>MEG issues Hazardous Weather Outlook (HWO) htt...</td>\n",
       "      <td>[-0.421695739030838, -0.19718565046787262, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>#CityofCalgary has activated its Municipal Eme...</td>\n",
       "      <td>[-0.3985871970653534, -0.22917336225509644, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "0                    Just happened a terrible car crash   \n",
       "1     Heard about #earthquake is different cities, s...   \n",
       "2     there is a forest fire at spot pond, geese are...   \n",
       "3              Apocalypse lighting. #Spokane #wildfires   \n",
       "4         Typhoon Soudelor kills 28 in China and Taiwan   \n",
       "...                                                 ...   \n",
       "3258  EARTHQUAKE SAFETY LOS ANGELES ÛÒ SAFETY FASTE...   \n",
       "3259  Storm in RI worse than last hurricane. My city...   \n",
       "3260  Green Line derailment in Chicago http://t.co/U...   \n",
       "3261  MEG issues Hazardous Weather Outlook (HWO) htt...   \n",
       "3262  #CityofCalgary has activated its Municipal Eme...   \n",
       "\n",
       "                                    sentence_embeddings  \n",
       "0     [-0.25721344351768494, -0.15935777127742767, -...  \n",
       "1     [0.02665054053068161, -0.25792196393013, 0.041...  \n",
       "2     [-0.21820902824401855, 0.044809360057115555, -...  \n",
       "3     [-0.2617347240447998, 0.05129344016313553, -0....  \n",
       "4     [-0.4326396882534027, -0.2646219730377197, -0....  \n",
       "...                                                 ...  \n",
       "3258  [-0.1371319741010666, -0.19958768784999847, 0....  \n",
       "3259  [-0.0810704380273819, -0.11629102379083633, 0....  \n",
       "3260  [-0.18644750118255615, -0.1975667029619217, -0...  \n",
       "3261  [-0.421695739030838, -0.19718565046787262, -0....  \n",
       "3262  [-0.3985871970653534, -0.22917336225509644, 0....  \n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-processed dataset of D1 test\n",
    "df_d1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ae8d306-4a8c-430f-91ca-205cd2a468c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for both D1 and D2\n",
    "from sklearn import preprocessing\n",
    "\n",
    "D1_labels = df_d1_train['target'].values\n",
    "\n",
    "##ordinal encoding of D2 labels - sentiments\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(['negative', 'neutral', 'positive'])\n",
    "df_d2['sentiment_label'] = le.transform(df_d2['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d497034-66e8-4431-bc83-f5756eef80d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentence_embeddings</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.08791296184062958, -0.07898502051830292, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.2562563717365265, -0.22554504871368408, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.2252037674188614, -0.052482422441244125, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.060340315103530884, -0.18566212058067322, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.06627045571804047, -0.03680921345949173, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27476</th>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.1049598827958107, 0.05494336783885956, 0.1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27477</th>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[-0.28235170245170593, -0.3820191025733948, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[0.07476642727851868, 0.024916866794228554, 0....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27479</th>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>[-0.22100362181663513, -0.1052432432770729, 0....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27480</th>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>[-0.21136300265789032, 0.13121014833450317, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1          Sooo SAD I will miss you here in San Diego!!!  negative   \n",
       "2                              my boss is bullying me...  negative   \n",
       "3                         what interview! leave me alone  negative   \n",
       "4       Sons of ****, why couldn`t they put them on t...  negative   \n",
       "...                                                  ...       ...   \n",
       "27476   wish we could come see u on Denver  husband l...  negative   \n",
       "27477   I`ve wondered about rake to.  The client has ...  negative   \n",
       "27478   Yay good for both of you. Enjoy the break - y...  positive   \n",
       "27479                         But it was worth it  ****.  positive   \n",
       "27480     All this flirting going on - The ATG smiles...   neutral   \n",
       "\n",
       "                                     sentence_embeddings  sentiment_label  \n",
       "0      [-0.08791296184062958, -0.07898502051830292, 0...                1  \n",
       "1      [-0.2562563717365265, -0.22554504871368408, 0....                0  \n",
       "2      [-0.2252037674188614, -0.052482422441244125, -...                0  \n",
       "3      [-0.060340315103530884, -0.18566212058067322, ...                0  \n",
       "4      [-0.06627045571804047, -0.03680921345949173, 0...                0  \n",
       "...                                                  ...              ...  \n",
       "27476  [-0.1049598827958107, 0.05494336783885956, 0.1...                0  \n",
       "27477  [-0.28235170245170593, -0.3820191025733948, -0...                0  \n",
       "27478  [0.07476642727851868, 0.024916866794228554, 0....                2  \n",
       "27479  [-0.22100362181663513, -0.1052432432770729, 0....                2  \n",
       "27480  [-0.21136300265789032, 0.13121014833450317, 0....                1  \n",
       "\n",
       "[27480 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pre-processed dataset of D2\n",
    "df_d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ec1f7e0-63b7-4be1-ad9a-bc902de88358",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train test split into 80/20 for both D1 and D2 dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "D1_text_train, D1_text_val, D1_labels_train, D1_labels_val = train_test_split(df_d1_train, df_d1_train['target'], test_size=0.2, random_state=0)\n",
    "D2_text_train, D2_text_val, D2_labels_train, D2_labels_val = train_test_split(df_d2, df_d2['sentiment_label'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e81697-afea-4d4d-aa6a-5b7d997f5d73",
   "metadata": {},
   "source": [
    "# II. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b841d66-fde2-41b1-9ee3-54561118bf9b",
   "metadata": {},
   "source": [
    "The neural network architecture consists of 3 hidden layers of 1024, 512 and 128 neurons respectively. the input layer has dimensions of 768 which is the dimension of the BERT features extraction output. The output layer is 2 (binary classification) for task 1 and 3 for task 2(multi-class classification). A dropout of 0.3 is used for each hidden layer output for prevention of overfitting. In addition, RELU is used as an activation function for the output of each hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b71b44b-7c99-402f-9c8c-e174e2fb02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataset and dataloader for Neural network training\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "D1_train_data = TensorDataset(torch.from_numpy(np.vstack(D1_text_train['sentence_embeddings'].values)).type(torch.float32), torch.from_numpy(D1_labels_train.values).type(torch.LongTensor))\n",
    "D1_train_dataloader = DataLoader(D1_train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "D1_val_data = TensorDataset(torch.from_numpy(np.vstack(D1_text_val['sentence_embeddings'].values)).type(torch.float32), torch.from_numpy(D1_labels_val.values).type(torch.LongTensor))\n",
    "D1_val_dataloader = DataLoader(D1_val_data, batch_size=512)\n",
    "\n",
    "D2_train_data = TensorDataset(torch.from_numpy(np.vstack(D2_text_train['sentence_embeddings'].values)).type(torch.float32), torch.from_numpy(D2_labels_train.values).type(torch.LongTensor))\n",
    "D2_train_dataloader = DataLoader(D2_train_data, batch_size=128, shuffle=True)\n",
    "\n",
    "D2_val_data = TensorDataset(torch.from_numpy(np.vstack(D2_text_val['sentence_embeddings'].values)).type(torch.float32), torch.from_numpy(D2_labels_val.values).type(torch.LongTensor))\n",
    "D2_val_dataloader = DataLoader(D2_val_data, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18e3eafd-5c5a-470c-bf6f-04e79c60ae42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 2,  ..., 0, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(D2_labels_val.values).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24ba2ba6-8230-428f-bb75-ef160d9e0ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fully connected network with sentence vectors as inputs\n",
    "\n",
    "import torch.nn as nn\n",
    "import random\n",
    "rng = 0\n",
    "class NeuralNetwork(nn.Module):\n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(768, 1024)\n",
    "        self.lin2 = nn.Linear(1024, 512)\n",
    "        self.lin3 = nn.Linear(512, 128)\n",
    "        self.lin4 = nn.Linear(128, n_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71ae14-d45a-47bc-a8d1-0227b7a7e20f",
   "metadata": {},
   "source": [
    "#### Assume the model is deployed in a server within your news agency. Explain the inputs to the model and predictions that it is expected to output. Also explain how the predictions will be used by reporters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35381603-4abb-4d92-a18e-5aecb6cb1cf2",
   "metadata": {},
   "source": [
    "The inputs to the model is real time tweets from online and the output to the model is  prediction if the tweet is talking about a disaster or not. Those predicted to be disasters will be used by reporters to be further investigated for their reports on disasters that are happening in their area."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745e3c3-bd24-4386-8fe2-bbfcf8f8e3e2",
   "metadata": {},
   "source": [
    "# III. Multi Task Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c072e-def9-4f28-b915-30192bbdfb3b",
   "metadata": {},
   "source": [
    "#### 1. Train the model M only for T1 in D1train. Call the trained model MD1. Evaluate MD1 on D1val and report its performance metric (F1 score) for the first task, PerfT1(MD1|D1val). Also print the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630e947c-300d-4ceb-af1c-ff987ca2a4c8",
   "metadata": {},
   "source": [
    "Utilising just the D1 train dataset which has been split into 80%/20% for training and validation, the model described above was trained. The trained model was evaluated using the validation dateset and the results of the performance on the validation set in terms of f1 score and the confusion matrix is shown below. The loss function used was Crossentropy and the optimizer used was Adam with a learning rate of 0.0001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e715441-2f36-4ef5-b559-f8f5ba724c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss: 0.5828595605368415\n",
      "Epoch 1: Training loss: 0.4736311997597416\n",
      "Epoch 2: Training loss: 0.4494618217771252\n",
      "Epoch 3: Training loss: 0.4469677365074555\n",
      "Epoch 4: Training loss: 0.4378945715725422\n",
      "Epoch 5: Training loss: 0.4349824154439072\n",
      "Epoch 6: Training loss: 0.4267571975166599\n",
      "Epoch 7: Training loss: 0.42033909540623426\n",
      "Epoch 8: Training loss: 0.4136833120137453\n",
      "Epoch 9: Training loss: 0.40615985558057827\n",
      "Epoch 10: Training loss: 0.4015836676893135\n",
      "Epoch 11: Training loss: 0.4031594387876491\n",
      "Epoch 12: Training loss: 0.3961522088696559\n",
      "Epoch 13: Training loss: 0.38524199835956097\n",
      "Epoch 14: Training loss: 0.3846547246600191\n",
      "Epoch 15: Training loss: 0.37687573954463005\n",
      "Epoch 16: Training loss: 0.3772066895229121\n",
      "Epoch 17: Training loss: 0.3659581035996477\n",
      "Epoch 18: Training loss: 0.3572805233610173\n",
      "Epoch 19: Training loss: 0.3538552025953929\n"
     ]
    }
   ],
   "source": [
    "rng = 0\n",
    "\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "M_D1 = NeuralNetwork(2)\n",
    "optimizer = torch.optim.Adam(M_D1.parameters(), lr = 0.0001)\n",
    "epochs = 20\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        l = 0\n",
    "        num_batches = 0\n",
    "        for xb, yb in D1_train_dataloader:\n",
    "            pred = M_D1(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            l += loss.detach().item()\n",
    "            num_batches += 1\n",
    "        print(f\"Epoch {epoch}: Training loss: {l/num_batches}\")\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "970b4b8e-87e7-4dbc-89ff-1572f3ab30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "truth = []\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in D1_val_dataloader:\n",
    "        x, y = data\n",
    "        output = M_D1(x)\n",
    "\n",
    "        class_probs_batch = [nn.Softmax(dim=0)(el) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "        truth.extend([l.item() for l in y])\n",
    "\n",
    "val_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "val_preds = torch.cat(class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "234911bc-d5d0-4fba-9e73-e9894cd0b37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of MD1 based on the first task is 0.7327823691460055\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "perf_t1_MD1 = f1_score(truth, val_preds)\n",
    "print(f'The f1 score of MD1 based on the first task is {perf_t1_MD1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a043996-d9b9-4d5c-86fb-6f973b2e2bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2aa8e6610>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, _ = plt.subplots(nrows=1, figsize=(5,5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(False)\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(truth, val_preds, labels=[0,1]), display_labels=[0,1])\n",
    "disp.plot(ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218403cb-49b7-4344-b8a8-3abf7d44d000",
   "metadata": {},
   "source": [
    "#### 2. Train the model M only for T2 on D2train. Call the trained model MD2. Evaluate the trained MD2 on D2val and report its performance metric (Accuracy) PerfT2(MD2|D2val). Also print the confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9eb84f-8313-408c-a544-bfe830ab0c22",
   "metadata": {},
   "source": [
    "Similar to the D1 train dataset, the D2 dataset was also trained and evaluated using the same model architecture. The same loss function was used. the optimizer used was Adam with a learning rate of 0.001. The results of the performance of the model on the validation set in terms of accuracy score and confusion matrix is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e5944b1-f6be-42e7-9978-a7f5ee6a96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Training loss: 0.8884962540726329\n",
      "Epoch 1: Training loss: 0.805613188202991\n",
      "Epoch 2: Training loss: 0.7828710113846978\n",
      "Epoch 3: Training loss: 0.7708117878714273\n",
      "Epoch 4: Training loss: 0.7674534778262294\n",
      "Epoch 5: Training loss: 0.7607348835052445\n",
      "Epoch 6: Training loss: 0.7571664209975753\n",
      "Epoch 7: Training loss: 0.7450087125911269\n",
      "Epoch 8: Training loss: 0.7440101119667984\n",
      "Epoch 9: Training loss: 0.7434442947770274\n",
      "Epoch 10: Training loss: 0.7371547967195511\n",
      "Epoch 11: Training loss: 0.7290339611990507\n",
      "Epoch 12: Training loss: 0.7255553672480028\n",
      "Epoch 13: Training loss: 0.7231831543667372\n",
      "Epoch 14: Training loss: 0.7185053243193515\n",
      "Epoch 15: Training loss: 0.715627055528552\n",
      "Epoch 16: Training loss: 0.7097152786892514\n",
      "Epoch 17: Training loss: 0.7029003556384597\n",
      "Epoch 18: Training loss: 0.7025264186221499\n",
      "Epoch 19: Training loss: 0.6973349545584169\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "M_D2 = NeuralNetwork(3)\n",
    "optimizer = torch.optim.Adam(M_D2.parameters(), lr = 0.001)\n",
    "epochs = 20\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        l = 0\n",
    "        num_batches = 0\n",
    "        for xb, yb in D2_train_dataloader:\n",
    "            pred = M_D2(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            l += loss.detach().item()\n",
    "            num_batches += 1\n",
    "        print(f\"Epoch {epoch}: Training loss: {l/num_batches}\")\n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "807af016-3f80-48cb-bbab-fbd4ceec6082",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "truth = []\n",
    "class_probs = []\n",
    "class_preds = []\n",
    "with torch.no_grad():\n",
    "    for data in D2_val_dataloader:\n",
    "        x, y = data\n",
    "        output = M_D2(x)\n",
    "        \n",
    "        class_probs_batch = [nn.Softmax(dim=0)(el) for el in output]\n",
    "        _, class_preds_batch = torch.max(output, 1)\n",
    "        class_probs.append(class_probs_batch)\n",
    "        class_preds.append(class_preds_batch)\n",
    "        truth.extend([l.item() for l in y])\n",
    "\n",
    "val_probs = torch.cat([torch.stack(batch) for batch in class_probs])\n",
    "val_preds = torch.cat(class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72512727-f3c3-40a4-a8bc-feefe1d9cc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of MD2 based on the second task is 0.637372634643377\n"
     ]
    }
   ],
   "source": [
    "\n",
    "perf_t2_MD2 = accuracy_score(val_preds, truth)\n",
    "print(f'The accuracy score of MD2 based on the second task is {perf_t2_MD2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9c1143e-4c84-4ce9-a3c4-2b988cb73862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2aade2940>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, _ = plt.subplots(nrows=1, figsize=(5,5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(False)\n",
    "\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(truth, val_preds, labels=[0,1,2]), display_labels=[0,1,2])\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845df0b-4e37-4852-bb70-efd0398c3469",
   "metadata": {},
   "source": [
    "#### 3. Estimate the sentiment labels for the tweets in D1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfc16df-2020-44db-87c9-b989245d2aee",
   "metadata": {},
   "source": [
    "An augmented dataset of D1 was created by using the model trained using D2 dataset to predict the sentiment labels for the tweets from the D1 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5b026023-3c05-4af2-90e5-8db8b0fc71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = M_D2(torch.from_numpy(np.vstack(df_d1_train['sentence_embeddings'].values)).type(torch.float32))\n",
    "    class_probs = [nn.Softmax(dim=0)(el) for el in output]\n",
    "    _, class_preds = torch.max(output, 1)\n",
    "    D1_labels_train_hat = class_preds.numpy()\n",
    "\n",
    "#Augmented dataset df\n",
    "df_d1_train_aug =  df_d1_train.copy()\n",
    "df_d1_train_aug['sentiment_label'] = convert_2darray_to_df(D1_labels_train_hat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e8369317-de72-4a6b-9036-d89bf5f5792c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>sentence_embeddings</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.10347555577754974, 0.0949205756187439, -0....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4164022207260132, 0.19298885762691498, -0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.2418411374092102, -0.1157110333442688, 0.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.12487819045782089, 0.030626526102423668, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0019691395573318005, -0.14926283061504364,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.2051445096731186, 0.09096449613571167, -0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.23618453741073608, -0.10245174914598465, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.35735654830932617, 0.006355086341500282, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.4586879014968872, -0.25744855403900146, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.19707342982292175, -0.10754090547561646, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  target  \\\n",
       "0     Our Deeds are the Reason of this #earthquake M...       1   \n",
       "1                Forest fire near La Ronge Sask. Canada       1   \n",
       "2     All residents asked to 'shelter in place' are ...       1   \n",
       "3     13,000 people receive #wildfires evacuation or...       1   \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1   \n",
       "...                                                 ...     ...   \n",
       "7608  Two giant cranes holding a bridge collapse int...       1   \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1   \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1   \n",
       "7611  Police investigating after an e-bike collided ...       1   \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1   \n",
       "\n",
       "                                    sentence_embeddings  sentiment_label  \n",
       "0     [-0.10347555577754974, 0.0949205756187439, -0....                2  \n",
       "1     [-0.4164022207260132, 0.19298885762691498, -0....                1  \n",
       "2     [-0.2418411374092102, -0.1157110333442688, 0.1...                1  \n",
       "3     [-0.12487819045782089, 0.030626526102423668, -...                1  \n",
       "4     [-0.0019691395573318005, -0.14926283061504364,...                1  \n",
       "...                                                 ...              ...  \n",
       "7608  [-0.2051445096731186, 0.09096449613571167, -0....                0  \n",
       "7609  [-0.23618453741073608, -0.10245174914598465, -...                0  \n",
       "7610  [-0.35735654830932617, 0.006355086341500282, 0...                1  \n",
       "7611  [-0.4586879014968872, -0.25744855403900146, -0...                0  \n",
       "7612  [-0.19707342982292175, -0.10754090547561646, -...                0  \n",
       "\n",
       "[7613 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_d1_train_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932f35f-35c2-4dc9-ad9e-a39b27e158d9",
   "metadata": {},
   "source": [
    "#### Analyze and report the predicted sentiment labels for some of the tweets from the disaster dataset. Use at least 1 tweet from each class for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98210a47-5e6c-466d-b0eb-c878870c8e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of negative sentiments:\n",
      "Texts:\n",
      "1. #RockyFire Update => California Hwy. 20 closed in both directions due to Lake County fire - #CAfire #wildfires\n",
      "2. Haha South Tampa is getting flooded hah- WAIT A SECOND I LIVE IN SOUTH TAMPA WHAT AM I GONNA DO WHAT AM I GONNA DO FVCK #flooding\n",
      "3. Damage to school bus on 80 in multi car crash #BREAKING \n",
      "\n",
      "\n",
      "Examples of positive sentiments:\n",
      "Text:\n",
      "1. Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
      "2. I love fruits\n",
      "3. Summer is lovely\n",
      "\n",
      "\n",
      "Examples of neutral sentiments:\n",
      "Text:\n",
      "1. Forest fire near La Ronge Sask. Canada\n",
      "2. All residents asked to 'shelter in place' are being notified by officers. No other evacuation or shelter in place orders are expected\n",
      "3. 13,000 people receive #wildfires evacuation orders in California \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of negative sentiments:\")\n",
    "print('Texts:')\n",
    "print(\"1.\", df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 0].iloc[0,0])\n",
    "print(\"2.\", df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 0].iloc[1,0])\n",
    "print(\"3.\", df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 0].iloc[3,0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Examples of positive sentiments:\")\n",
    "print('Text:')\n",
    "print(\"1.\", df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 2].iloc[0,0])\n",
    "print(\"2.\", df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 2].iloc[1,0])\n",
    "print(\"3.\", df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 2].iloc[2,0])\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Examples of neutral sentiments:\")\n",
    "print('Text:')\n",
    "print(\"1.\", df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 1].iloc[0,0])\n",
    "print(\"2.\",df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 1].iloc[1,0])\n",
    "print(\"3.\",df_d1_train_aug[df_d1_train_aug['sentiment_label'] == 1].iloc[2,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1d8a3-152e-4d2c-9499-4eec04adbdb8",
   "metadata": {},
   "source": [
    "As shown in the examples above for the predicted negative, positive and nuetral sentiments, it is able to correctly predict the postive sentiments and negative sentiments(disaster tweets) relatively well. However, the neutral sentiments are not that well predicted as alot of the disaster tweets are predicted as neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75292bab-edf6-411e-800e-d9b369a3b9ec",
   "metadata": {},
   "source": [
    "#### 4. Create another dataset by combining D1 and D2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ac7e89-941c-42c8-83f0-1f984942de99",
   "metadata": {},
   "source": [
    "Another dataset was also created where the D1 train dataset was merged with the D2 train dataset with both labels and tweets. In this dataset, whereever the labels are missing for each tweet, it is retained as null. The combined dataset is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b543f977-8e7f-49ed-8dc3-a2b1461cb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_D2_train_combine_df = D1_text_train.merge(D2_text_train, on='text', how='outer').drop(['sentiment'], axis=1)\n",
    "\n",
    "D1_D2_train_combine_df = D1_D2_train_combine_df.rename(columns = {'sentence_embeddings_x': 'sentence_embeddings_D1', 'sentence_embeddings_y': 'sentence_embeddings_D2'})\n",
    "\n",
    "def sentence_embeddings_combine(row):\n",
    "    if np.isnan(row['sentence_embeddings_D1']).all():\n",
    "        return row['sentence_embeddings_D2']\n",
    "    else:\n",
    "        return row['sentence_embeddings_D1']\n",
    "    \n",
    "D1_D2_train_combine_df['sentence_embeddings'] = D1_D2_train_combine_df.apply(sentence_embeddings_combine, axis=1)\n",
    "D1_D2_train_combine_df = D1_D2_train_combine_df.drop(['sentence_embeddings_D1', 'sentence_embeddings_D2'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d78aacf3-158d-4d2a-8f3d-c195533e4c94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>sentence_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ted Cruz fires back at Jeb &amp;amp; Bush: ÛÏWe l...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.20338654518127441, -0.14267973601818085, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is the first year the Forest Service spen...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.32133790850639343, -0.10172615945339203, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@lightseraphs pissed at you and could have the...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.09641452133655548, -0.19245226681232452, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm gonna fight Taylor as soon as I get there.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.04530864953994751, -0.041303567588329315, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@NicolaClements4 IÛªm not sure that covering ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.4246214032173157, 0.0069144354201853275, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28069</th>\n",
       "      <td>...thanks for the shout out...you might be ri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-0.09515293687582016, 0.06759532541036606, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28070</th>\n",
       "      <td>Im going in now, it looks like the sun has gone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.07051143795251846, 0.21059899032115936, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28071</th>\n",
       "      <td>I am soooo saying this phrase now 'Stop be so ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.1425376832485199, 0.03949875757098198, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28072</th>\n",
       "      <td>Morning all  and its a lovely day at last</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[-0.1805098056793213, -0.27493786811828613, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28073</th>\n",
       "      <td>Editors read this and nod, writers read this a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.1842319369316101, -0.16171422600746155, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28074 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target  \\\n",
       "0      Ted Cruz fires back at Jeb &amp; Bush: ÛÏWe l...     0.0   \n",
       "1      This is the first year the Forest Service spen...     1.0   \n",
       "2      @lightseraphs pissed at you and could have the...     0.0   \n",
       "3         I'm gonna fight Taylor as soon as I get there.     0.0   \n",
       "4      @NicolaClements4 IÛªm not sure that covering ...     0.0   \n",
       "...                                                  ...     ...   \n",
       "28069   ...thanks for the shout out...you might be ri...     NaN   \n",
       "28070    Im going in now, it looks like the sun has gone     NaN   \n",
       "28071  I am soooo saying this phrase now 'Stop be so ...     NaN   \n",
       "28072          Morning all  and its a lovely day at last     NaN   \n",
       "28073  Editors read this and nod, writers read this a...     NaN   \n",
       "\n",
       "       sentiment_label                                sentence_embeddings  \n",
       "0                  NaN  [-0.20338654518127441, -0.14267973601818085, -...  \n",
       "1                  NaN  [-0.32133790850639343, -0.10172615945339203, -...  \n",
       "2                  NaN  [-0.09641452133655548, -0.19245226681232452, 0...  \n",
       "3                  NaN  [-0.04530864953994751, -0.041303567588329315, ...  \n",
       "4                  NaN  [-0.4246214032173157, 0.0069144354201853275, 0...  \n",
       "...                ...                                                ...  \n",
       "28069              2.0  [-0.09515293687582016, 0.06759532541036606, 0....  \n",
       "28070              1.0  [-0.07051143795251846, 0.21059899032115936, 0....  \n",
       "28071              1.0  [-0.1425376832485199, 0.03949875757098198, 0.0...  \n",
       "28072              2.0  [-0.1805098056793213, -0.27493786811828613, 0....  \n",
       "28073              1.0  [-0.1842319369316101, -0.16171422600746155, 0....  \n",
       "\n",
       "[28074 rows x 4 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1_D2_train_combine_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4538ee-eec9-498b-8b15-7a9b41c065a7",
   "metadata": {},
   "source": [
    "#### 5. Train M for both T1 and T2 on D12 by minimizing a weighted loss, λ1l1 + λ2l2 where λs are positive scalar weights between and 1: higher the λ more the emphasis on corresponding task while training; l1, l2 are task-specific loss functions. Call this model MD12.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4968df8-2fcd-4eab-9a8d-6bfbf7423c8b",
   "metadata": {},
   "source": [
    "A multitask learning(MTL) model was built using the same architecture as the individual models stated in previous sections. Using the merged dataset in Section 4, the model is trained for both tasks. A simple schematic of the model is shown below."
   ]
  },
  {
   "attachments": {
    "3fc3b42a-8b98-4b85-8a84-7e2566adfd28.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "a51835f2-6a17-4953-8604-c1538a15429c",
   "metadata": {},
   "source": [
    "![hardparameter.png](attachment:3fc3b42a-8b98-4b85-8a84-7e2566adfd28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d4e0f4-f8d4-4b69-bb62-1864624b36e7",
   "metadata": {},
   "source": [
    "This MTL model is described as a hard parameter sharing model where both the tasks share the same hidden layers. Therefore, the weights are the same for the hidden layers for both the tasks. A hyperparameter term lambda1 and lambda2 is used to combine the loss function for the gradients to be computed and the weights to be updated in each batch as part of the training.\n",
    "\n",
    "#### When the label of a data sample is , the corresponding loss is considered as 0. What is the effect of this during network training?\n",
    "\n",
    "If a label is null for a particular observation, the loss is calculated as zero for that particular task. The loss from this lable is not use for backpropagation to update the weights for the shared hidden layers. This just means that the model is trained focusing on the task which has a label and not focus on the task where the label is null as the weights are updated at each batch based on the combined loss function. \n",
    "\n",
    "The model MD12 is trained using the combined dataset and the performance of the model is evaluated using the validation set(20% split) of the augmented dataset. A lambda value of 0.5 is used for both lambdas. The evaluation in terms of f1 score for task 1 and accuracy score for task 2 is shown below. The confusion matrices for both tasks on the validation dataset are also detailed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "131b1e1b-1726-4373-a364-7684d2fd075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-task model Architecture\n",
    "class MultiTaskNeuralNetwork(nn.Module):\n",
    "    def __init__(self, n_classes_task1, n_classes_task2):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(768, 1024)\n",
    "        self.lin2 = nn.Linear(1024, 512)\n",
    "        self.lin3 = nn.Linear(512, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Task-specific output layers\n",
    "        self.out_task1 = nn.Linear(128, n_classes_task1)\n",
    "        self.out_task2 = nn.Linear(128, n_classes_task2)\n",
    "        \n",
    "    def forward(self, x, task):\n",
    "        x = self.lin1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Task-specific outputs\n",
    "        if task == 1:\n",
    "            return self.out_task1(x)\n",
    "        if task == 2:\n",
    "            return self.out_task2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9206debe-d8d9-41b8-845f-1a8df1916a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "D12_train_data = TensorDataset(torch.from_numpy(np.vstack(D1_D2_train_combine_df['sentence_embeddings'].values)).type(torch.float32), torch.from_numpy(D1_D2_train_combine_df['target'].values), torch.from_numpy(D1_D2_train_combine_df['sentiment_label'].values))\n",
    "D12_train_dataloader = DataLoader(D12_train_data, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0164116-454c-4179-8526-922e0973b8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(torch.from_numpy(D1_D2_train_combine_df['target'].values))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=28074, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29cd8b3-4c0c-490e-b755-719430e807e2",
   "metadata": {},
   "source": [
    "#### After training with λ1 = λ2 = 0.5, evaluate MD12 on D1_hat_val and report the performance for both the tasks. Print confusion matrices for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2392cee-00f0-4ba6-95e9-4b7fbb07859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5301852797185641\n",
      "Epoch 2, Loss: 0.4304850555633901\n",
      "Epoch 3, Loss: 0.41082929468507917\n",
      "Epoch 4, Loss: 0.40112957229375296\n",
      "Epoch 5, Loss: 0.39383074817733504\n",
      "Epoch 6, Loss: 0.3895439106402473\n",
      "Epoch 7, Loss: 0.38536120038097704\n",
      "Epoch 8, Loss: 0.3803299713650706\n",
      "Epoch 9, Loss: 0.3758257447926493\n",
      "Epoch 10, Loss: 0.37180413068155493\n",
      "Epoch 11, Loss: 0.36785031770247806\n",
      "Epoch 12, Loss: 0.3660173841788177\n",
      "Epoch 13, Loss: 0.36170643554461573\n",
      "Epoch 14, Loss: 0.35800651795228683\n",
      "Epoch 15, Loss: 0.35379083461397604\n",
      "Epoch 16, Loss: 0.34999145268715054\n",
      "Epoch 17, Loss: 0.34694199725680036\n",
      "Epoch 18, Loss: 0.3426519400505922\n",
      "Epoch 19, Loss: 0.33846259049239624\n",
      "Epoch 20, Loss: 0.33417507795646684\n"
     ]
    }
   ],
   "source": [
    "# Train model with lambda1 = 0.5 and lambda2 = 0.5 - Hyperparameters for the loss functions\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "lambda_1 = 0.5\n",
    "lambda_2 = 0.5\n",
    "epochs = 20\n",
    "\n",
    "MD_12 = MultiTaskNeuralNetwork(n_classes_task1=2, n_classes_task2=3)\n",
    "\n",
    "# Define separate loss functions for each task\n",
    "criterion_task1 = nn.CrossEntropyLoss()\n",
    "criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(MD_12.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for (inputs, labels_task1, labels_task2) in D12_train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        idx1 = labels_task1 != np.nan\n",
    "        idx2 = labels_task2 != np.nan\n",
    "        input1 = inputs[idx1]\n",
    "        input2 = inputs[idx2]\n",
    "        \n",
    "        # Forward pass\n",
    "        #outputs_task1, outputs_task2 = MD_12(inputs)\n",
    "        outputs_task1 = MD_12(input1, task=1)\n",
    "        outputs_task2 = MD_12(input2, task=2)\n",
    "        \n",
    "        #print(labels_task1)\n",
    "        # Compute the losses for each task\n",
    "        loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "        loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "        # Combine the losses with the hyperparameters as factors\n",
    "        loss = lambda_1 * loss_task1 + lambda_2 * loss_task2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(D12_train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "275f87cd-7677-48ef-9668-21dc2edc9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1_hat_train, D1_hat_val = train_test_split(df_d1_train_aug, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "27c46c77-23ad-4720-9e08-f7d24e42535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader for D1_hat for validation\n",
    "D1_hat_val_data = TensorDataset(torch.from_numpy(np.vstack(D1_hat_val['sentence_embeddings'].values)).type(torch.float32), torch.from_numpy(D1_hat_val['target'].values).type(torch.LongTensor), torch.from_numpy(D1_hat_val['sentiment_label'].values).type(torch.LongTensor))\n",
    "D1_hat_val_dataloader = DataLoader(D1_hat_val_data, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "41006d28-083f-4206-8a8f-e5d904c3b4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation of model using D1_hat validation data\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "truth1 = []\n",
    "truth2 = []\n",
    "class_probs_t1 = []\n",
    "class_probs_t2 = []\n",
    "class_preds_t1 = []\n",
    "class_preds_t2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in D1_hat_val_dataloader:\n",
    "        x, y1, y2 = data\n",
    "        output_t1 = MD_12(x, task = 1)\n",
    "        output_t2 = MD_12(x, task = 2)\n",
    "        \n",
    "        class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "        class_probs_t2_batch = [nn.Softmax(dim=0)(el) for el in output_t2]\n",
    "        \n",
    "        _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "        _, class_preds_t2_batch = torch.max(output_t2, 1)\n",
    "\n",
    "        class_probs_t1.append(class_probs_t1_batch)\n",
    "        class_probs_t2.append(class_probs_t2_batch)\n",
    "        \n",
    "        class_preds_t1.append(class_preds_t1_batch)\n",
    "        class_preds_t2.append(class_preds_t2_batch)\n",
    "        \n",
    "        truth1.extend([l.item() for l in y1])\n",
    "        truth2.extend([l.item() for l in y2])\n",
    "\n",
    "val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "val_probs_t2 = torch.cat([torch.stack(batch) for batch in class_probs_t2])\n",
    "val_preds_t1 = torch.cat(class_preds_t1)\n",
    "val_preds_t2 = torch.cat(class_preds_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "e1ffdfd6-dd0c-4051-a388-41ad7abff14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of MD12 based on the first task is 0.7418502202643172\n",
      "The accuracy score of MD12 based on the second task is 0.41628365068942874\n"
     ]
    }
   ],
   "source": [
    "#Task 1 and Task 2 performance score for lambda1=0.5 and lambda2=0.5\n",
    "perf_t1_MD12 = f1_score(truth1, val_preds_t1)\n",
    "print(f'The f1 score of MD12 based on the first task is {perf_t1_MD12}')\n",
    "\n",
    "perf_t2_MD12 = accuracy_score(truth2, val_preds_t2)\n",
    "print(f'The accuracy score of MD12 based on the second task is {perf_t2_MD12}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "44e5cb80-8a08-4eda-b1f7-2690380bb4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion matrix of task 1 from MD12 model is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2cc4d9250>"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix for task 1 for lambda1=0.5 and lambda2=0.5\n",
    "print('the confusion matrix of task 1 from MD12 model is:')\n",
    "fig, _ = plt.subplots(nrows=1, figsize=(5,5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(False)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(truth1, val_preds_t1, labels=[0,1]), display_labels=[0,1])\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "874fcdba-57e1-420b-b4dd-c926caf7e11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion matrix of task 2 from MD12 model is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2c6602f10>"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix for task 2 for lambda1=0.5 and lambda2=0.5\n",
    "print('the confusion matrix of task 2 from MD12 model is:')\n",
    "fig, _ = plt.subplots(nrows=1, figsize=(5,5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(False)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(truth2, val_preds_t2, labels=[0,1,2]), display_labels=[0,1,2])\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ba65c7-0380-43a4-9ff0-cc7a8bf6afc8",
   "metadata": {},
   "source": [
    "### 6. Obtain the best values of the hyperparameters to optimise for classification for Task 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d5c00-53ec-497b-a3e1-814b6312d2ae",
   "metadata": {},
   "source": [
    "To optimise the model based on our primary task 1 performance, the hyperparameters lambda1 and lambda2 are gridsearched(each lambda ranging from 0 to 1) to find the best combination that gives the best performance for task 1 which is our primary task. The results of the hyperparameter tuning exercise is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "b50ebc62-5918-4837-a0c1-c7b88212457d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a function to train and evaluate the model based on a given \n",
    "## lambda1 and lambda2\n",
    "\n",
    "def train_and_evaluate_model(lambda_1, lambda_2, train_dataloader, val_dataloader):\n",
    "    \n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    MD_12 = MultiTaskNeuralNetwork(n_classes_task1=2, n_classes_task2=3)\n",
    "\n",
    "    epochs = 20\n",
    "\n",
    "    # Define separate loss functions for each task\n",
    "    criterion_task1 = nn.CrossEntropyLoss()\n",
    "    criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(MD_12.parameters(), lr=0.0001)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for (inputs, labels_task1, labels_task2) in train_dataloader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            idx1 = labels_task1 != np.nan\n",
    "            idx2 = labels_task2 != np.nan\n",
    "            input1 = inputs[idx1]\n",
    "            input2 = inputs[idx2]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs_task1 = MD_12(input1, task=1)\n",
    "            outputs_task2 = MD_12(input2, task=2)\n",
    "\n",
    "            # Compute the losses for each task\n",
    "            loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "            loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "            # Combine the losses with the hyperparameters as factors\n",
    "            loss = lambda_1 * loss_task1 + lambda_2 * loss_task2\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # # Print the average loss for this epoch\n",
    "        #print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(D12_train_dataloader)}\")\n",
    "\n",
    "    #Evalution of model\n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    truth1 = []\n",
    "    truth2 = []\n",
    "    class_probs_t1 = []\n",
    "    class_probs_t2 = []\n",
    "    class_preds_t1 = []\n",
    "    class_preds_t2 = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            x, y1, y2 = data\n",
    "            output_t1 = MD_12(x, task = 1)\n",
    "            output_t2 = MD_12(x, task = 2)\n",
    "\n",
    "            class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "            class_probs_t2_batch = [nn.Softmax(dim=0)(el) for el in output_t2]\n",
    "\n",
    "            _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "            _, class_preds_t2_batch = torch.max(output_t2, 1)\n",
    "\n",
    "            class_probs_t1.append(class_probs_t1_batch)\n",
    "            class_probs_t2.append(class_probs_t2_batch)\n",
    "\n",
    "            class_preds_t1.append(class_preds_t1_batch)\n",
    "            class_preds_t2.append(class_preds_t2_batch)\n",
    "\n",
    "            truth1.extend([l.item() for l in y1])\n",
    "            truth2.extend([l.item() for l in y2])\n",
    "\n",
    "    val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "    val_probs_t2 = torch.cat([torch.stack(batch) for batch in class_probs_t2])\n",
    "    val_preds_t1 = torch.cat(class_preds_t1)\n",
    "    val_preds_t2 = torch.cat(class_preds_t2)    \n",
    "    \n",
    "    perf_t1_MD12 = f1_score(truth1, val_preds_t1)\n",
    "    perf_t2_MD12 = accuracy_score(truth2, val_preds_t2)    \n",
    "\n",
    "    return perf_t1_MD12, perf_t2_MD12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "a83b2d4e-e805-4fc9-97ed-fb59d3507a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda_1: 0, Lambda_2: 0, Task 1 Validation f1_score: 0.5863039399624765\n",
      "Lambda_1: 0, Lambda_2: 0.25, Task 1 Validation f1_score: 0.008849557522123894\n",
      "Lambda_1: 0, Lambda_2: 0.5, Task 1 Validation f1_score: 0.0029629629629629632\n",
      "Lambda_1: 0, Lambda_2: 0.75, Task 1 Validation f1_score: 0.0029761904761904765\n",
      "Lambda_1: 0, Lambda_2: 1.0, Task 1 Validation f1_score: 0.0\n",
      "Lambda_1: 0.25, Lambda_2: 0, Task 1 Validation f1_score: 0.7530017152658661\n",
      "Lambda_1: 0.25, Lambda_2: 0.25, Task 1 Validation f1_score: 0.7542147293700089\n",
      "Lambda_1: 0.25, Lambda_2: 0.5, Task 1 Validation f1_score: 0.74447391688771\n",
      "Lambda_1: 0.25, Lambda_2: 0.75, Task 1 Validation f1_score: 0.7405452946350043\n",
      "Lambda_1: 0.25, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7430025445292621\n",
      "Lambda_1: 0.5, Lambda_2: 0, Task 1 Validation f1_score: 0.7564766839378237\n",
      "Lambda_1: 0.5, Lambda_2: 0.25, Task 1 Validation f1_score: 0.74447391688771\n",
      "Lambda_1: 0.5, Lambda_2: 0.5, Task 1 Validation f1_score: 0.7418502202643172\n",
      "Lambda_1: 0.5, Lambda_2: 0.75, Task 1 Validation f1_score: 0.7383512544802867\n",
      "Lambda_1: 0.5, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7407407407407407\n",
      "Lambda_1: 0.75, Lambda_2: 0, Task 1 Validation f1_score: 0.7547826086956523\n",
      "Lambda_1: 0.75, Lambda_2: 0.25, Task 1 Validation f1_score: 0.741125541125541\n",
      "Lambda_1: 0.75, Lambda_2: 0.5, Task 1 Validation f1_score: 0.74447391688771\n",
      "Lambda_1: 0.75, Lambda_2: 0.75, Task 1 Validation f1_score: 0.7359154929577466\n",
      "Lambda_1: 0.75, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7510993843447669\n",
      "Lambda_1: 1.0, Lambda_2: 0, Task 1 Validation f1_score: 0.7534722222222222\n",
      "Lambda_1: 1.0, Lambda_2: 0.25, Task 1 Validation f1_score: 0.7447916666666666\n",
      "Lambda_1: 1.0, Lambda_2: 0.5, Task 1 Validation f1_score: 0.7482394366197183\n",
      "Lambda_1: 1.0, Lambda_2: 0.75, Task 1 Validation f1_score: 0.7411347517730495\n",
      "Lambda_1: 1.0, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7340425531914894\n"
     ]
    }
   ],
   "source": [
    "#do a gridsearch on lambda1 and lambda2 to find best lambdas for task 1 performance\n",
    "lambda_1_list = [0, 0.25, 0.5, 0.75, 1.0] \n",
    "lambda_2_list = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "best_lambda_1 = None\n",
    "best_lambda_2 = None\n",
    "best_t1_val_perf = 0\n",
    "\n",
    "## Run all combinations of lambda1 and lambda2 to find best combination for best \n",
    "## T1 performance\n",
    "for lambda_1 in lambda_1_list:\n",
    "\n",
    "    for lambda_2 in lambda_2_list:\n",
    "        \n",
    "        task1_val_perf, task2_val_perf = train_and_evaluate_model(lambda_1, lambda_2, D12_train_dataloader, D1_hat_val_dataloader)\n",
    "        \n",
    "        print(f\"Lambda_1: {lambda_1}, Lambda_2: {lambda_2}, Task 1 Validation f1_score: {task1_val_perf}\")\n",
    "        \n",
    "        if task1_val_perf > best_t1_val_perf:\n",
    "            best_t1_val_perf = task1_val_perf\n",
    "            best_lambda_1 = lambda_1\n",
    "            best_lambda_2 = lambda_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "d864a3bd-e59f-46c3-b27d-a268a0ab8fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda_1 value is: 0.5\n",
      "The best lambda_2 value is: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best lambda_1 value is: {best_lambda_1}\")\n",
    "print(f\"The best lambda_2 value is: {best_lambda_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166993e8-f157-4f64-948a-ddcd2f233bc3",
   "metadata": {},
   "source": [
    "#### 7. Train the model on with the best λs obtained in step 6. Evaluate it on D1test for the tasks and report PerfT1(M*D12|D1test) by participating in the challenge. Submit a screenshot of your leaderboard score and position."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5f8c33-755c-4485-b848-1b5eaa0f7fd3",
   "metadata": {},
   "source": [
    "The best lambdas to use for the best performance for task 1 is lambda1 = 0.5 and lambda2 = 0. These hyperparameters are used to re-train the model. The re-trained optimised for task 1 model is then used to predict the labels for the D1 test dataset to be submitted in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28080b20-c03b-42e7-95a4-e1e1421945d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.08508400533535011\n",
      "Epoch 2, Loss: 0.061049835463659094\n",
      "Epoch 3, Loss: 0.05886150733408665\n",
      "Epoch 4, Loss: 0.05695856657252564\n",
      "Epoch 5, Loss: 0.05533848590469985\n",
      "Epoch 6, Loss: 0.05416584508238967\n",
      "Epoch 7, Loss: 0.052747852484014625\n",
      "Epoch 8, Loss: 0.051984266274033755\n",
      "Epoch 9, Loss: 0.051056703271509775\n",
      "Epoch 10, Loss: 0.0503111632762515\n",
      "Epoch 11, Loss: 0.04981572580139804\n",
      "Epoch 12, Loss: 0.04833769537126624\n",
      "Epoch 13, Loss: 0.048265669159676054\n",
      "Epoch 14, Loss: 0.04663654399774799\n",
      "Epoch 15, Loss: 0.046400111095962836\n",
      "Epoch 16, Loss: 0.045006322100597324\n",
      "Epoch 17, Loss: 0.043547674485297706\n",
      "Epoch 18, Loss: 0.0428064103038867\n",
      "Epoch 19, Loss: 0.04138571462659738\n",
      "Epoch 20, Loss: 0.0403988613823433\n"
     ]
    }
   ],
   "source": [
    "# Re-train model with lambda_1 = 0.5 and lambda_2 = 0\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "lambda_1 = 0.5\n",
    "lambda_2 = 0.0\n",
    "epochs = 20\n",
    "\n",
    "MD_12_test = MultiTaskNeuralNetwork(n_classes_task1=2, n_classes_task2=3)\n",
    "# Define separate loss functions for each task\n",
    "criterion_task1 = nn.CrossEntropyLoss()\n",
    "criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(MD_12_test.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for (inputs, labels_task1, labels_task2) in D12_train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        idx1 = labels_task1 != np.nan\n",
    "        idx2 = labels_task2 != np.nan\n",
    "        input1 = inputs[idx1]\n",
    "        input2 = inputs[idx2]        \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs_task1 = MD_12_test(input1, task=1)\n",
    "        outputs_task2 = MD_12_test(input2, task=2)\n",
    "\n",
    "        # Compute the losses for each task\n",
    "        loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "        loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "        # Combine the losses with the hyperparameters as factors\n",
    "        loss = lambda_1 * loss_task1 + lambda_2 * loss_task2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(D12_train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9881eb50-d901-4f79-9ba2-0befde94a7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load D1 test file with ID column and concat with original D1 test df\n",
    "df_d1_test_id = pd.read_csv('test.csv')\n",
    "df_d1_test_id = df_d1_test_id['id']\n",
    "df_d1_test_final = pd.concat([df_d1_test_id, df_d1_test], axis=1)\n",
    "\n",
    "# D1 test dataset in dataset loader\n",
    "test_dataset = TensorDataset(torch.from_numpy(np.vstack(df_d1_test_final['sentence_embeddings'].values)).type(torch.float32))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=3263)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "66eedc69-7823-449b-b521-72f51e8e5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict trained model test dataset to be submitted in Kaggle\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "class_probs_t1 = []\n",
    "class_preds_t1 = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        x = data\n",
    "        output_t1 = MD_12_test(x[0], task = 1)\n",
    "        \n",
    "        class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "        \n",
    "        _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "\n",
    "        class_probs_t1.append(class_probs_t1_batch)\n",
    "        \n",
    "        class_preds_t1.append(class_preds_t1_batch)\n",
    "        \n",
    "\n",
    "#predictions of D1 test data\n",
    "val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "val_preds_t1 = torch.cat(class_preds_t1).numpy()\n",
    "\n",
    "#write prediction of test data to output for submission to kaggle\n",
    "df_d1_MD12_test_preds = df_d1_test_final\n",
    "df_d1_MD12_test_preds['target'] = val_preds_t1.tolist()\n",
    "df_d1_MD12_test_preds = df_d1_MD12_test_preds.drop(['text', 'sentence_embeddings'], axis=1)\n",
    "df_d1_MD12_test_preds.to_csv('test_hard_parameter.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045959ef",
   "metadata": {},
   "source": [
    "### The model resulted in Score of 80.14% in Kaggle.(Please refer screenshot in the zip file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf80d06d-2d70-4416-ae37-db17d4f47f46",
   "metadata": {},
   "source": [
    "#### 8. In step 7, you performed multi-task learning, where data for the second taskis externally sourced. Is the best value of hyper-parameter λ2 from step 6 zero or positive, i.e., is λ2 = 0 or λ2 > 0 ? What does the value of λ2 convey? Does the externally sourced sentiment data improve the model accuracy for our primary task of disaster classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3536591b-14c9-4601-b2bf-0782e82ec7ce",
   "metadata": {},
   "source": [
    "As shown in the results above, the best results for predicting task 1 is when lambda2 is zero. This means that when lambda2 is zero, the model is more focused on training for the task 1 as it only updates the weights based on the gradient of the loss function of task 1 during backpropagation. The value of lambda2 conveys the importance we want to give to task 2 prediction when training the model.\n",
    "\n",
    "However, we would expect the model to give the same results as MD1 model in section 1 as lambda2 is zero(loss function for task2 is always zero) and that would mean the backpropagation to update the weights would only be done using loss fuction for task 1. But we are getting better slightly better results with MD12 model compared to MD1 model. This is probably due to using a larger dataset (combine D1 and D2). While training backpropagation per batch, a combination of D1 and D2 data is passed for loss calculation compared to just D1 data alone in MD1 model. Therefore, the backpropagation and loss calculation is different in MD12 model compared to MD1 model even though the loss function is calculated only using D1 dataset for both (lambda2 is zero). \n",
    "\n",
    "Therefore, using the externally sourced sentiment data does improve the overall accuracy of task 1 using the MTL model MD12 compared to only training the model based on D1 train dataset as shown in section 1 as it improves generalizability of the predictions by preventing overfitting to D1 dataset alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9189f66c-8f89-4efe-af79-68f2cc66dbfb",
   "metadata": {},
   "source": [
    "#### 9. For multi-task learning why is the augmented dataset D1_hat used only for testing but not for training?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0a56d-6cb5-440c-929e-0c356943e43b",
   "metadata": {},
   "source": [
    "The augmented dataset is used only for testing and not for training due to the fact that the labels used for sentiments in the augmented dataset are not true labels and are predicted from the model trained using the D2 dataset. As the prediction accuracy is low for the model trained using the D2 dataset as shown in Section 2, the labels will not be suitable for training them as true labels in the MTL model. Since we are testing for our primary task, the augmented dataset can be used for testing as the labels for task 1 are true labels in the augmented dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56f23dd",
   "metadata": {},
   "source": [
    "# Part IV: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf123b4",
   "metadata": {},
   "source": [
    "#### 1. How can the MTL strategy of loss combination in question 5 (part III) be used with a Random Forest? Explain.\n",
    "\n",
    "Random Forests are a type of decision tree-based ensemble model that doesn't use a loss function during training. Instead, the Random Forest algorithm trains decision trees on random subsets of the input data and features, and combines the results to make predictions.One way to do this is to modify the splitting criterion of the decision trees to take into account the multi-task objective\n",
    "\n",
    "The Information Gain and Gain Ratio criteria of each split Si is calculated by combine the main classification\n",
    "task and the second task, showing below.\n",
    "\n",
    "MTIG(Si) = MainTaskIG(Si) + weight ∗ SecondTaskIG(Si) \n",
    "\n",
    "In this equation, MainTaskIG(Si) is the information gain of the main task, which is the task that is being optimized in the decision tree split. SecondTaskIG(Si) is the information gain of the extra task, which is a related task that is being considered along with the main task.\n",
    "\n",
    "The weight parameter in the equation is a tuning parameter that determines the relative importance of the main task and the Second task in the decision-making process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5841320",
   "metadata": {},
   "source": [
    "#### 2.  Try the following approach: Use the augmented dataset obtained in question 3 (part III) to train a Random Forest for prediction of label 1, use the predicted sentiment labels for weighting the samples while fitting the Random Forest.Evaluate the model on D1_hat_val and report the performance and print confusion matrix\n",
    "\n",
    "Here we have trained a random forest model using the augmented dataset.We have randomly selected below lambda values(equal sample weights).\n",
    "\n",
    "lambda_p = 0.5\n",
    "lambda_n = 0.5\n",
    "lambda_0 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "793a2542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Extracting the sentence embedding from train data\n",
    "X_train = np.vstack(D1_hat_train['sentence_embeddings'].values)\n",
    "y_train = D1_hat_train['target']\n",
    "train_label_2 = D1_hat_train['sentiment_label']\n",
    "\n",
    "#Extracting the sentence embedding from validation data\n",
    "X_val = np.vstack(D1_hat_val['sentence_embeddings'].values)\n",
    "y_val = D1_hat_val['target']\n",
    "\n",
    "\n",
    "#Sentiment Label Weights chosen randomly: \n",
    "lambda_p = 0.5\n",
    "lambda_n = 0.5\n",
    "lambda_0 = 0.5\n",
    "\n",
    "#Assignng weights to the samples\n",
    "sample_weights_label2 = np.where(train_label_2 == 2, lambda_p,\n",
    "                          np.where(train_label_2 == 0, lambda_n,\n",
    "                          lambda_0))\n",
    "\n",
    "# create a Random Forest model with sample weights\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state = 0)\n",
    "\n",
    "# fit the model using sample weights\n",
    "model.fit(X_train, y_train, sample_weight = sample_weights_label2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32541841",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Running predictions on validation dataset\n",
    "y_val_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "614894b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of Random Forest based on the first task is 0.7335640138408305\n"
     ]
    }
   ],
   "source": [
    "perf_t1_RF = f1_score(y_val, y_val_pred)\n",
    "print(f'The f1 score of Random Forest based on the first task is {perf_t1_RF}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c51e14de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion matrix Random Forest based on the first task is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x23843ec7550>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbsAAAGaCAYAAACWme2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA560lEQVR4nO3de1xUdfoH8M9wmeEiM3KRGUdHRcW8gEpgpFaQAubm7edu1mqFRaVhFqvGbrG7UiqUv1RSytJ1lTTTfutitWsmdKHMLCQsRbNSVDBGtJA7MzBzfn+Qp0YkZ5zBceZ83q/XedWc+Z7vPBDx8Dzne86RCYIggIiIyI15ODsAIiKirsZkR0REbo/JjoiI3B6THRERuT0mOyIicntMdkRE5PaY7IiIyO15OTsAIiLqWi0tLTAajQ6ZSy6Xw8fHxyFzXUtMdkREbqylpQVhfbtBX21yyHwajQbl5eUul/CY7IiI3JjRaIS+2oRTJf2gDLDvzFVdvRl9o0/CaDQy2RER0fWnW4AM3QJkds1hhn3HOxOTHRGRBJgEM0x23gnZJJgdE4wTcDUmERG5PVZ2REQSYIYAM+wr7ew93pmY7IiIJMAMM+xtQto/g/OwjUlERG6PlR0RkQSYBAEmO5/Vbe/xzsRkR0QkAVI/Z8c2JhERuT1WdkREEmCGAJOEKzsmOyIiCWAbk4iIyM2xsiMikgCuxiQiIrdn/nmzdw5XxTYmERG5PVZ2REQSYHLAakx7j3cmJjsiIgkwCXDAI34cE4szsI1JRERuj5UdEZEESH2BCpMdEZEEmCGDCTK753BVbGMSEZHbY2VHRCQBZqF9s3cOV8VkR0QkASYHtDHtPd6Z2MYkIiK3x8qOiEgCpF7ZMdkREUmAWZDBLNi5GtPO452JbUwiInJ7rOyIiCSAbUwiInJ7JnjAZGczz+SgWJyBbUwiInJ7rOyIiCRAcMACFcGFF6gw2RERSYDUz9mxjUlERG6PlR0RkQSYBA+YBDsXqPDemEREdD0zQwaznc08M1w327l0sjObzfjhhx8QEBAAmcx1e8lERBcJgoD6+npotVp4ePBMk6O4dLL74YcfoNPpnB0GEZHDVVRUoHfv3g6bT+oLVFw62QUEBAAATn3ZD8pu/AuIutb/DIp0dggkAW1oxV7sEn+/OYpjztmxjekUF1uXym4eUAYw2VHX8pJ5OzsEkoKf8wlPzTiWSyc7IiKyTvsCFTufesA2JhERXc/MDrg3piuvxmTvj4iI3B4rOyIiCeACFSIicntmeEj6onK2MYmIyO2xsiMikgCTIIPJzkf02Hu8M7GyIyKSgItPKrd3s0W/fv0gk8k6bPPmzQPQfmu0zMxMaLVa+Pr6Ij4+HmVlZRZzGAwGzJ8/HyEhIfD398eUKVNQWVlp89fPZEdERF2iuLgYVVVV4lZQUAAAuOuuuwAAy5cvx8qVK5Gbm4vi4mJoNBokJiaivr5enCMtLQ35+fnYtm0b9u7di4aGBkyaNAkmk8mmWJjsiIgkwCx4OGSzRY8ePaDRaMTtP//5DwYMGIC4uDgIgoCcnBxkZGRg+vTpiIiIQF5eHpqamrB161YAQG1tLTZs2IAVK1YgISEBUVFR2LJlCw4dOoTCwkKbYmGyIyKSAEe2Mevq6iw2g8Fwxc83Go3YsmULHnzwQchkMpSXl0Ov1yMpKUkco1AoEBcXh3379gEASkpK0NraajFGq9UiIiJCHGMtJjsiIrKJTqeDSqUSt+zs7Cses3PnTly4cAGzZ88GAOj1egCAWq22GKdWq8X39Ho95HI5AgMDOx1jLa7GJCKSADPsX01p/vmfFRUVUCqV4n6FQnHFYzds2ICJEydCq9Va7L/0hteCIFzxJtjWjLkUKzsiIgm4eFG5vRsAKJVKi+1Kye7UqVMoLCzEQw89JO7TaDQA0KFCq66uFqs9jUYDo9GImpqaTsdYi8mOiIi61MaNGxEaGoo777xT3BcWFgaNRiOu0ATaz+sVFRVhzJgxAIDo6Gh4e3tbjKmqqsLhw4fFMdZiG5OISAIcc29M2483m83YuHEjkpOT4eX1S8qRyWRIS0tDVlYWwsPDER4ejqysLPj5+WHmzJkAAJVKhZSUFCxcuBDBwcEICgrCokWLEBkZiYSEBJviYLIjIpIAZz3PrrCwEKdPn8aDDz7Y4b309HQ0NzcjNTUVNTU1iI2NxZ49eyye0r5q1Sp4eXlhxowZaG5uxvjx47Fp0yZ4enraFIdMEFz3NtZ1dXVQqVSo+bY/n1ROXW6CdqSzQyAJaBNa8RHeQm1trcUikKt18ffk6pKb4dvNvvqmuaENj0fvd1hs1xIrOyIiCXBWG/N6wWRHRCQBV3Nvy8vN4apcN3IiIiIrsbIjIpIAsyCD2d6Lyl34ET9MdkREEmB2QBvT3iedO5PrRk5ERGQlVnZERBJwNY/oudwcrorJjohIAkyQwWTnReX2Hu9MrpumiYiIrMTKjohIAtjGJCIit2eC/W1Ik2NCcQrXTdNERERWYmVHRCQBbGMSEZHbk/qNoF03ciIiIiuxsiMikgDBAQ9vFVz4OjsmOyIiCWAbk4iIyM2xsiMikgA+4oeIiNwen1RORETk5ljZERFJANuYRETk9szwsPtJ43xSORER0XWMlR0RkQSYBBlMdrYh7T3emZjsiIgkQOrn7NjGJCIit8fKjohIAgQHPOJHcOHbhTHZERFJgAkyBzypnG1MIiKi6xYrOyIiCTAL9i8wMQsOCsYJmOyIiCTA7IBzdvYe70yuGzkREZGVWNkREUmA2QFPKrf3eGdisiMikgCp30GFbUwiInJ7rOyIiCRA6gtUmOyIiCTADAfcG9OFz9m5bpomIiKyEis7IiIJEBywGlNw4cqOyY6ISAL4iB8iIiI3x8qOiEgCuBqTiIjcHtuYREREXeTMmTO49957ERwcDD8/P4wcORIlJSXi+4IgIDMzE1qtFr6+voiPj0dZWZnFHAaDAfPnz0dISAj8/f0xZcoUVFZW2hQHkx0RkQRcvDemvZstampqMHbsWHh7e+Pdd9/FkSNHsGLFCnTv3l0cs3z5cqxcuRK5ubkoLi6GRqNBYmIi6uvrxTFpaWnIz8/Htm3bsHfvXjQ0NGDSpEkwmUxWx8I2JhGRBDijjfn8889Dp9Nh48aN4r5+/fqJ/y4IAnJycpCRkYHp06cDAPLy8qBWq7F161bMmTMHtbW12LBhAzZv3oyEhAQAwJYtW6DT6VBYWIgJEyZYFQsrOyIiskldXZ3FZjAYLjvu7bffRkxMDO666y6EhoYiKioK69evF98vLy+HXq9HUlKSuE+hUCAuLg779u0DAJSUlKC1tdVijFarRUREhDjGGkx2REQScLGys3cDAJ1OB5VKJW7Z2dmX/cwTJ05g7dq1CA8Px3vvvYe5c+fi8ccfx2uvvQYA0Ov1AAC1Wm1xnFqtFt/T6/WQy+UIDAzsdIw12MYkIiKbVFRUQKlUiq8VCsVlx5nNZsTExCArKwsAEBUVhbKyMqxduxb333+/OE4ms2yPCoLQYd+lrBnza6zsiIgkwJGVnVKptNg6S3Y9e/bE0KFDLfYNGTIEp0+fBgBoNBoA6FChVVdXi9WeRqOB0WhETU1Np2OswWTnBu6/aSgmaEd22HKf6gUAqDnnhRfS+uCPUcMwpf9wPD2zP86ckF92LkEAMmb1xwTtSOx7V3UtvwxyYb7+Jsx95gxe++II3j7+NVa9/R0GjWgCAHh6CUjJ+AGvvH8Mb31/CFu/LMOTL55GkLrVyVFLiyOTnbXGjh2LY8eOWez79ttv0bdvXwBAWFgYNBoNCgoKxPeNRiOKioowZswYAEB0dDS8vb0txlRVVeHw4cPiGGs4Pdm9/PLLCAsLg4+PD6Kjo/HJJ584OySXs/rdY3jj4GFxy972PQDg1sm1EATgmQfDUHVKjsyNJ/DSnmNQ9zbiL3cPREtTx//8+et7wIbOABEA4E8rKnDjbfVYPr8P5o6/ASVFAXhu+3EEa1qh8DVjYGQztuaoMW9COJ59qB969TfgmU3lzg6butif/vQn7N+/H1lZWfj++++xdetWrFu3DvPmzQPQ3r5MS0tDVlYW8vPzcfjwYcyePRt+fn6YOXMmAEClUiElJQULFy7E+++/j9LSUtx7772IjIwUV2daw6nJbvv27UhLS0NGRgZKS0tx6623YuLEiWKJS9bpHmxCUGibuH1eqELPfgYMH92AMycUOFrij/nPVeKGkc3QDTTgsexKNDd54MP87hbzHC/zwY5Xe2DBSn7/yXpyHzNu+V0t/rFUi8Ofd8MPJxXYskIDfYUck+4/j6Z6Tzx1zwB8/E53VB73wTdf+uPlv/bCoBHN6NHL6OzwJUOA/dfaCTZ+5qhRo5Cfn4833ngDERERWLJkCXJycjBr1ixxTHp6OtLS0pCamoqYmBicOXMGe/bsQUBAgDhm1apVmDZtGmbMmIGxY8fCz88P77zzDjw9Pa2OxanJbuXKlUhJScFDDz2EIUOGICcnBzqdDmvXrnVmWC6t1SjDBzsCMeGeHyGTtb8GALnCLI7x9AS8vQWUFXcT97U0yfBcaj/MW1aJoNC2ax43uS5PTwGeXoDRYNkSMDR7YNhNjZc9xl9pgtkMNNZa/8uK7OOMNiYATJo0CYcOHUJLSwuOHj2Khx9+2OJ9mUyGzMxMVFVVoaWlBUVFRYiIiLAY4+PjgzVr1uDHH39EU1MT3nnnHeh0OpvicFqyMxqNKCkpsbh2AgCSkpI6vXbCYDB0uL6DLO3brUJDnSeSZvwEANANbIG6txH/zO6J+gueaDXKsH1NKH6q9sZPZ39ZjPtqZi8MjWnEmDv4PSXbNDd64sgBP8xMO4sgdSs8PASMm16DwTc2IUjd8Q8nb4UZDz5dhQ/zu6OpgcmOrg2nJbvz58/DZDL95vUVl8rOzra4tsPWzC4F770RhFG31yFY0/5Lxssb+Ns/ynHmuA/+MDQSUwYMx1efdcOocXXw+Pn3zGfvKXHw0wDMffaMEyMnV7Z8fh/IZMAbpUfwn5NfY1rKOXyY3x3mS+7m5Okl4Om1pyDzAHKf6u2cYCXKWZXd9cLp19nZcn3FU089hQULFoiv6+rqmPB+5WylN0o/CcDf/mF54j98eDPWFh5DY50HWltl6B5swuN3hmPQ8PbVcgc/DUDVSTmmD460OG7Jw/0QEduI/93x/TX7Gsg1VZ1S4MnfD4TC1wT/ADN+qvbG06+chP70L6t+Pb0EZLx6EhqdEekzBrCqu8ak/tQDpyW7kJAQeHp6/ub1FZdSKBSdXs9BwJ5twege0obYhMu3Iv2V7eftzpyQ47uv/JD8ZPv3/u7HzmLizB8txs4ZNxhzMs/g5iS2Ncl6hmZPGJo90U3Vhui4evxjqRbAL4muV5gR6X8YgPoap/+dTRLjtJ84uVyO6OhoFBQU4H/+53/E/QUFBZg6daqzwnJZZjOwZ3sQEu76CZ6X/Ff9+B0VVMEmhPYyovyoD175e2+MvqMW0fHtdxW/uIrzUqG9WqHpw9VydGXRcXWQyYCK4wr0CjPiob/9gMrjPtizPQgengL+tv4kBkY24+/3h8HDU0Bgj/Zr7OoveKKt1elXQEkCKzsnWrBgAe677z7ExMRg9OjRWLduHU6fPo25c+c6MyyXVPpxAKrPyDHhnp86vPfTWW+8mtkLF857ISi0DQl3/YSZaWedECW5K3+lGQ88VYWQnq2ov+CJT3epsPG5njC1yaDubcToCe0dgrWF31oc9+TvB+Drz7pdbkpyMEGQQbAzWdl7vDM5Ndndfffd+PHHH/Hss8+iqqoKERER2LVrl3h1PVkvOr4e7/1w8LLvTXvoPKY9dN6m+Tqbi+hyPn6nOz5+p/tl3ztbKccE7YhrGxDRJZzeOE9NTUVqaqqzwyAicmtX8/DVy83hqpye7IiIqOtJ/ZwdzwwTEZHbY2VHRCQBXKBCRERuj21MIiIiN8fKjohIAtjGJCIityc4oI3pysmObUwiInJ7rOyIiCRAACDY+qjxy8zhqpjsiIgkwAwZZBK+gwrbmERE5PZY2RERSQBXYxIRkdszCzLIeFE5ERGR+2JlR0QkAYLggNWYLrwck8mOiEgCpH7Ojm1MIiJye6zsiIgkQOqVHZMdEZEEcDUmERGRm2NlR0QkAVyNSUREbq892dl7zs5BwTgB25hEROT2WNkREUkAV2MSEZHbE2D/8+hcuIvJNiYREbk/VnZERBLANiYREbk/ifcx2cYkIiK3x8qOiEgKHNDGBNuYRER0PZP6HVTYxiQiIrfHyo6ISAK4GpOIiNyfILP/nJsLJzu2MYmIyO2xsiMikgAuUCEiIvcnOGizQWZmJmQymcWm0Wh+CUkQkJmZCa1WC19fX8THx6OsrMxiDoPBgPnz5yMkJAT+/v6YMmUKKisrbf7ymeyIiKjLDBs2DFVVVeJ26NAh8b3ly5dj5cqVyM3NRXFxMTQaDRITE1FfXy+OSUtLQ35+PrZt24a9e/eioaEBkyZNgslksikOtjGJiCTAkasx6+rqLPYrFAooFIrLHuPl5WVRzf0yl4CcnBxkZGRg+vTpAIC8vDyo1Wps3boVc+bMQW1tLTZs2IDNmzcjISEBALBlyxbodDoUFhZiwoQJVsduVbJbvXq11RM+/vjjVo8lIqJryEHn3HQ6ncXrxYsXIzMz87Jjv/vuO2i1WigUCsTGxiIrKwv9+/dHeXk59Ho9kpKSxLEKhQJxcXHYt28f5syZg5KSErS2tlqM0Wq1iIiIwL59+xyf7FatWmXVZDKZjMmOiMjNVVRUQKlUiq87q+piY2Px2muvYdCgQTh79iyWLl2KMWPGoKysDHq9HgCgVqstjlGr1Th16hQAQK/XQy6XIzAwsMOYi8dby6pkV15ebtOkRER0fXFkG1OpVFoku85MnDhR/PfIyEiMHj0aAwYMQF5eHm6++WYA7UWS5WcIHfZ1jOPKYy511QtUjEYjjh07hra2tqudgoiIrhUnrMa8lL+/PyIjI/Hdd9+J5/EurdCqq6vFak+j0cBoNKKmpqbTMdayOdk1NTUhJSUFfn5+GDZsGE6fPg2g/Vzdc889Z+t0REQkEQaDAUePHkXPnj0RFhYGjUaDgoIC8X2j0YiioiKMGTMGABAdHQ1vb2+LMVVVVTh8+LA4xlo2J7unnnoKX331FT766CP4+PiI+xMSErB9+3ZbpyMiomtC5qDNeosWLUJRURHKy8vx+eef4w9/+APq6uqQnJwMmUyGtLQ0ZGVlIT8/H4cPH8bs2bPh5+eHmTNnAgBUKhVSUlKwcOFCvP/++ygtLcW9996LyMhIcXWmtWy+9GDnzp3Yvn07br75Zoue6dChQ3H8+HFbpyMiomvBCU8qr6ysxB//+EecP38ePXr0wM0334z9+/ejb9++AID09HQ0NzcjNTUVNTU1iI2NxZ49exAQECDOsWrVKnh5eWHGjBlobm7G+PHjsWnTJnh6etoUi83J7ty5cwgNDe2wv7Gx0eYThkRE5L62bdv2m+/LZDJkZmZ2etkCAPj4+GDNmjVYs2aNXbHY3MYcNWoU/vvf/4qvLya49evXY/To0XYFQ0REXeQ6WKDiTDZXdtnZ2bjjjjtw5MgRtLW14cUXX0RZWRk+++wzFBUVdUWMRERkLz7ixzZjxozBp59+iqamJgwYMAB79uyBWq3GZ599hujo6K6IkYiIyC5XdW/MyMhI5OXlOToWIiLqIlJ/xM9VJTuTyYT8/HwcPXoUMpkMQ4YMwdSpU+HlxftKExFdl5ywGvN6YnN2Onz4MKZOnQq9Xo8bbrgBAPDtt9+iR48eePvttxEZGenwIImIiOxh8zm7hx56CMOGDUNlZSW+/PJLfPnll6ioqMDw4cPxyCOPdEWMRERkr4sLVOzdXJTNld1XX32FAwcOWNyFOjAwEMuWLcOoUaMcGhwRETmGTGjf7J3DVdlc2d1www04e/Zsh/3V1dUYOHCgQ4IiIiJyJKsqu18/lTYrKwuPP/44MjMzxUc07N+/H88++yyef/75romSiIjswwUqV9a9e3eLW4EJgoAZM2aI+4Sf16NOnjwZJpOpC8IkIiK7SPyicquS3YcfftjVcRAREXUZq5JdXFxcV8dBRERdiW3Mq9PU1ITTp0/DaDRa7B8+fLjdQRERkYMx2dnm3LlzeOCBB/Duu+9e9n2esyMiouuNzZcepKWloaamBvv374evry92796NvLw8hIeH4+233+6KGImIyF58xI9tPvjgA7z11lsYNWoUPDw80LdvXyQmJkKpVCI7Oxt33nlnV8RJRET2kPhqTJsru8bGRvFJ5UFBQTh37hyA9ichfPnll46NjoiIyAGu6g4qx44dAwCMHDkSr776Ks6cOYNXXnkFPXv2dHiARERkv4u3C7N3c1U2tzHT0tJQVVUFAFi8eDEmTJiA119/HXK5HJs2bXJ0fERE5AhcjWmbWbNmif8eFRWFkydP4ptvvkGfPn0QEhLi0OCIiIgcwe6nrfr5+eHGG290RCxERERdwqpkt2DBAqsnXLly5VUHQ0REXUMGBzzixyGROIdVya60tNSqyX59s+hradr9M+Hl5eOUzybpOJnt6+wQSALMLS1A5lvODsPt8EbQRERSIPHr7Ow+Z0dERC5A4qsxbb7OjoiIyNWwsiMikgKJV3ZMdkREEuCIO6C48h1U2MYkIiK3d1XJbvPmzRg7diy0Wi1OnToFAMjJycFbb3G5LBHRdUnij/ixOdmtXbsWCxYswO9+9ztcuHBBfFhr9+7dkZOT4+j4iIjIEZjsbLNmzRqsX78eGRkZ8PT0FPfHxMTg0KFDDg2OiIjIEWxeoFJeXo6oqKgO+xUKBRobGx0SFBERORYXqNgoLCwMBw8e7LD/3XffxdChQx0RExEROdrFO6jYu7komyu7J598EvPmzUNLSwsEQcAXX3yBN954A9nZ2fjHP/7RFTESERHZxeZk98ADD6CtrQ3p6eloamrCzJkz0atXL7z44ou45557uiJGIiKyFy8qt93DDz+Mhx9+GOfPn4fZbEZoaKij4yIiIgeS+jk7u+6gwieTExGRK7A52YWFhf3mc+tOnDhhV0BERNQF2Ma0TVpamsXr1tZWlJaWYvfu3XjyyScdFRcRETmSA9qYkkp2TzzxxGX3v/TSSzhw4IDdARERETmaw24EPXHiROzYscNR0xERkSNJ/HZhDnvEz7/+9S8EBQU5ajoiInIkiZ+zs7myi4qKwo033ihuUVFR6NmzJ55++mk8/fTTXREjERG5uOzsbMhkMot1H4IgIDMzE1qtFr6+voiPj0dZWZnFcQaDAfPnz0dISAj8/f0xZcoUVFZW2vz5Nld206ZNs3jt4eGBHj16ID4+HoMHD7Y5ACIi6nrOvM6uuLgY69atw/Dhwy32L1++HCtXrsSmTZswaNAgLF26FImJiTh27BgCAgIAtC+KfOedd7Bt2zYEBwdj4cKFmDRpEkpKSiweRnAlNiW7trY29OvXDxMmTIBGo7HlUCIichN1dXUWrxUKBRQKxWXHNjQ0YNasWVi/fj2WLl0q7hcEATk5OcjIyMD06dMBAHl5eVCr1di6dSvmzJmD2tpabNiwAZs3b0ZCQgIAYMuWLdDpdCgsLMSECROsjtmmNqaXlxceffRRGAwGWw4jIiI3otPpoFKpxC07O7vTsfPmzcOdd94pJquLysvLodfrkZSUJO5TKBSIi4vDvn37AAAlJSVobW21GKPVahERESGOsZbNbczY2FiUlpaib9++th5KRETO4sAFKhUVFVAqleLuzqq6bdu24csvv0RxcXGH9/R6PQBArVZb7Fer1Th16pQ4Ri6XIzAwsMOYi8dby+Zkl5qaioULF6KyshLR0dHw9/e3eP/SniwRETmfI8/ZKZVKi2R3ORUVFXjiiSewZ88e+Pj4dD7nJXfkEgThN+/SZe2YS1md7B588EHk5OTg7rvvBgA8/vjj4nsymUz8cJPJZFMARETkfkpKSlBdXY3o6Ghxn8lkwscff4zc3FwcO3YMQHv11rNnT3FMdXW1WO1pNBoYjUbU1NRYVHfV1dUYM2aMTfFYfc4uLy8PLS0tKC8v77CdOHFC/CcREV2nruEF5ePHj8ehQ4dw8OBBcYuJicGsWbNw8OBB9O/fHxqNBgUFBeIxRqMRRUVFYiKLjo6Gt7e3xZiqqiocPnzY5mRndWUnCO1fKc/VERG5oGt8UXlAQAAiIiIs9vn7+yM4OFjcn5aWhqysLISHhyM8PBxZWVnw8/PDzJkzAQAqlQopKSlYuHAhgoODERQUhEWLFiEyMrLDgpcrsemcna09UiIios6kp6ejubkZqampqKmpQWxsLPbs2SNeYwcAq1atgpeXF2bMmIHm5maMHz8emzZtsukaOwCQCRdLtivw8PCASqW6YsL76aefbArAHnV1dVCpVIi7+a/w8ur8BCiRI5yc5OvsEEgCzC0tKM/MQG1t7RUXgVjj4u/J8PQseCrs+z1pMrTgu+VPOyy2a8mmyu6ZZ56BSqXqqliIiKirSPzemDYlu3vuuQehoaFdFQsREVGXsDrZ8XwdEZHrcua9Ma8HNq/GJCIiF8Q2pnXMZnNXxkFERNRlHPbwViIiuo6xsiMiIncn9XN2Nj+pnIiIyNWwsiMikgK2MYmIyO1JPNmxjUlERG6PlR0RkQRIfYEKkx0RkRSwjUlEROTeWNkREUkA25hEROT+2MYkIiJyb6zsiIikQOKVHZMdEZEEyH7e7J3DVbGNSUREbo+VHRGRFLCNSURE7k7qlx6wjUlERG6PlR0RkRSwjUlERJLgwsnKXmxjEhGR22NlR0QkAVJfoMJkR0QkBRI/Z8c2JhERuT1WdkREEsA2JhERuT+2MYmIiNwbKzsiIglgG5OIiNwf25hERETujZUdEZEUSLyyY7IjIpIAqZ+zYxuTiIjcHis7IiIpYBuTiIjcnUwQIBPsy1b2Hu9MbGMSEZHbY2XnBu6ZdghjY09B16sWRqMXjhzrgX+8Ho3KH1TimLE3ncKdid8ivP+PUCkNmPvkZJw4GdRhriGDqvHAH0sxeOB5tJlkOH4yCBlZCTAa+aNCHc2J+BILo7/ApiORyCoeCy+ZCWlRxYjrfRq6bnWob5Xjs6reeKEkFtXN/uJxd4cfwaT+32FY0Hl0k7cieusDqG9VOPErkQC2McnVRQ7T4+33BuPb74Ph6Slg9h9Lkf3XAjz8p6loMXgDAHx82lB2LBQff9YXCx797LLzDBlUjayMQmzLj8RLG25Ca5snBvT7CYJZdi2/HHIRkcHVmDHoKL75KVjc5+PVhmHB5/DyVzfim5oQKOUGZNz0KdaO243f//f3FuM+OdMHn5zpg0XRnzsjfMnhakwn+vjjjzF58mRotVrIZDLs3LnTmeG4rIxliSj4aCBOVQbixKkgrHh5LNQ9GhHe/0dxzPsfD8Dr/xqB0kPaTueZm1yMnbuGYPvOSJyqDMQPeiU+2d8PrW2e1+LLIBfi59WKF259H3/7LA61Rrm4v6FVgQcKJuPdUwNRXtcdX51XY8nntyAy5Bx6+teL4/KODse6w1E4eC7UGeHTNbJ27VoMHz4cSqUSSqUSo0ePxrvvviu+LwgCMjMzodVq4evri/j4eJSVlVnMYTAYMH/+fISEhMDf3x9TpkxBZWWlzbE4Ndk1NjZixIgRyM3NdWYYbsffzwgAqG+wvi3UXdmMIYPO40KtD1Yt3YXt67fjhWd2Y9jgs10VJrmwxbGf4KMzfbCvqvcVxwbIjTALQJ2RbUqnEhy02aB379547rnncODAARw4cADjxo3D1KlTxYS2fPlyrFy5Erm5uSguLoZGo0FiYiLq63/5wygtLQ35+fnYtm0b9u7di4aGBkyaNAkmk8mmWJzaxpw4cSImTpxo9XiDwQCDwSC+rqur64qwXJyAOcnFOHQ0FCcrAq0+SqNuAADcN+MrrHstGsdPBiEx7jie//sePLJgKn7QK7sqYHIxd/b7HkODz+P3/5l+xbFyjzYsvPFzvHMiHI2t8iuOp67jjDbm5MmTLV4vW7YMa9euxf79+zF06FDk5OQgIyMD06e3/yzl5eVBrVZj69atmDNnDmpra7FhwwZs3rwZCQkJAIAtW7ZAp9OhsLAQEyZMsDoWl1qNmZ2dDZVKJW46nc7ZIV13Hkv5HGF9apCdc5tNx3n8/FP834JB2PNROI6fDMYreTeh8gcV7hj3XVeESi5I49eAjJs+xZOfjIPR/Nt/K3vJTMiJK4SHTEDm57deowjpWqirq7PYfl2EdMZkMmHbtm1obGzE6NGjUV5eDr1ej6SkJHGMQqFAXFwc9u3bBwAoKSlBa2urxRitVouIiAhxjLVcKtk99dRTqK2tFbeKigpnh3RdSX3wc4yOqUD6MxNw/if/Kx/wKz9d8AUAnK5UWew/fUaF0JBGh8VIri0i+BxCfJvx70k7cOS+V3HkvlcRq6nC/UMO4ch9r8JDZgbQnuhejC9A7271eKBgEqu664ED25g6nc6i8MjOzu70Yw8dOoRu3bpBoVBg7ty5yM/Px9ChQ6HX6wEAarXaYrxarRbf0+v1kMvlCAwM7HSMtVxqNaZCoYBCwb5/RwLmpXyOsTedxqLFd0BfHWDzDPrqbjj/ky96ay1bw7171qG4tJejAiUX91lVL9z51gyLfc+N/RAnartj3eEomAUPMdH1DajFfe9NwQWDj5OipV9zZBuzoqICSuUvpzZ+6/fyDTfcgIMHD+LChQvYsWMHkpOTUVRU9MucMsvV3oIgdNh3KWvGXMqlkh1d3vyHPsftt5zA4uXj0NzijcDuzQCAxiZv8fq4gG4G9AhpRHBgEwBAp60FANRc8EXNBV8AMvzfWxG4/+6DOHEqUDxnp+tViyUr4pzyddH1p7FNju8uWF6f2dTmhRqDD767EARPmRmr4wswLPgc5rw/EZ4yASE+7T9ztUYFWs3tK3tDfJrQw7cJfZXtf1zdEPgTGlu98UNjN9QamRyvdxdXV1pDLpdj4MCBAICYmBgUFxfjxRdfxJ///GcA7dVbz549xfHV1dVitafRaGA0GlFTU2NR3VVXV2PMmDE2xcxk5wYmTzgGAFjxzHsW+//3pbEo+Kj9h+zmmAo8Oe9T8b2MP30MANj85ghs/r+RAID8XUMhl5swN7kYAd2MOH4qEH9Zkoiqs1ycQtbR+DUgoc9JAMDbU/5l8d69uyfji7PtXYI/3lCG+SNLxPe2TnwLAPDnvfHIPz742gQrNdfJReWCIMBgMCAsLAwajQYFBQWIiooCABiNRhQVFeH5558HAERHR8Pb2xsFBQWYMaO9o1BVVYXDhw9j+fLlNn2uU5NdQ0MDvv/+e/F1eXk5Dh48iKCgIPTp08eJkbmWpLuSrzim4KOBYuL7Ldt3RmL7zkhHhEUScd97U8V/P9OoxKC8uVc8Zs1Xo7Dmq1FdGRZdxrW+KPzpp5/GxIkTodPpUF9fj23btuGjjz7C7t27IZPJkJaWhqysLISHhyM8PBxZWVnw8/PDzJkzAQAqlQopKSlYuHAhgoODERQUhEWLFiEyMlJcnWktpya7AwcO4PbbbxdfL1iwAACQnJyMTZs2OSkqIiJyhLNnz+K+++5DVVUVVCoVhg8fjt27dyMxMREAkJ6ejubmZqSmpqKmpgaxsbHYs2cPAgJ+WXewatUqeHl5YcaMGWhubsb48eOxadMmeHradrMLmSC47m2s6+rqoFKpEHfzX+HlxT4/da2Tk3ydHQJJgLmlBeWZGaitrbX6vNhvufh7MvqupfDytu/3ZFtrC0r+768Oi+1a4jk7IiIJ4L0xiYiI3BwrOyIiKbhOVmM6C5MdEZEEyMztm71zuCq2MYmIyO2xsiMikgK2MYmIyN1xNSYREZGbY2VHRCQFgtC+2TuHi2KyIyKSALYxiYiI3BwrOyIiKeBqTCIicndsYxIREbk5VnZERFLA1ZhEROTu2MYkIiJyc6zsiIikgKsxiYjI3bGNSURE5OZY2RERSYFZaN/sncNFMdkREUmBxM/ZsY1JRERuj5UdEZEEyOCABSoOicQ5WNkREZHbY2VHRCQFvF0YERG5O15nR0RE5OZY2RERSYHELz1gsiMikgCZIEBm5zk3e493JrYxiYjI7bGyIyKSAvPPm71zuCgmOyIiCWAbk4iIyM2xsiMikgKuxiQiIrcn8TuosI1JRERuj5UdEZEESP12YUx2RERSwDYmERGRe2NlR0QkATJz+2bvHK6KyY6ISArYxiQiInJvrOyIiKRA4heVs7IjIpKAi/fGtHezRXZ2NkaNGoWAgACEhoZi2rRpOHbsmMUYQRCQmZkJrVYLX19fxMfHo6yszGKMwWDA/PnzERISAn9/f0yZMgWVlZU2xcJkR0REXaKoqAjz5s3D/v37UVBQgLa2NiQlJaGxsVEcs3z5cqxcuRK5ubkoLi6GRqNBYmIi6uvrxTFpaWnIz8/Htm3bsHfvXjQ0NGDSpEkwmUxWx8I2JhGRFDhhgcru3bstXm/cuBGhoaEoKSnBbbfdBkEQkJOTg4yMDEyfPh0AkJeXB7Vaja1bt2LOnDmora3Fhg0bsHnzZiQkJAAAtmzZAp1Oh8LCQkyYMMGqWFjZERFJgYBfnml3tdvPua6urs5iMxgMVoVQW1sLAAgKCgIAlJeXQ6/XIykpSRyjUCgQFxeHffv2AQBKSkrQ2tpqMUar1SIiIkIcYw0mOyIisolOp4NKpRK37OzsKx4jCAIWLFiAW265BREREQAAvV4PAFCr1RZj1Wq1+J5er4dcLkdgYGCnY6zBNiYRkQQ48uGtFRUVUCqV4n6FQnHFYx977DF8/fXX2Lt3b8d5ZTKL14IgdNh3KWvG/BorOyIiKRDwy3m7q97ap1IqlRbblZLd/Pnz8fbbb+PDDz9E7969xf0ajQYAOlRo1dXVYrWn0WhgNBpRU1PT6RhrMNkREVGXEAQBjz32GP7973/jgw8+QFhYmMX7YWFh0Gg0KCgoEPcZjUYUFRVhzJgxAIDo6Gh4e3tbjKmqqsLhw4fFMdZgG5OISAqcsBpz3rx52Lp1K9566y0EBASIFZxKpYKvry9kMhnS0tKQlZWF8PBwhIeHIysrC35+fpg5c6Y4NiUlBQsXLkRwcDCCgoKwaNEiREZGiqszrcFkR0QkBWYA1p/i6nwOG6xduxYAEB8fb7F/48aNmD17NgAgPT0dzc3NSE1NRU1NDWJjY7Fnzx4EBASI41etWgUvLy/MmDEDzc3NGD9+PDZt2gRPT0+rY2GyIyKiLiFYUQnKZDJkZmYiMzOz0zE+Pj5Ys2YN1qxZc9WxMNkREUmAI1djuiImOyIiKeAjfoiIiNwbKzsiIimQeGXHZEdEJAUST3ZsYxIRkdtjZUdEJAVOuM7uesJkR0QkAVK/9IBtTCIicnus7IiIpEDiC1SY7IiIpMAsADI7k5XZdZMd25hEROT2WNkREUkB25hEROT+HJDswGTnFBcfH9HWZnByJCQF5hZ7L1IiujJzSwsA6x6PQ9Zz6WRXX18PAPj0wP86ORKShP3ODoCkpL6+HiqVynETso3purRaLSoqKhAQEACZjH91W6uurg46nQ4VFRVQKpXODofcGH/WbCcIAurr66HVah07sVmA3W1IF16N6dLJzsPDA71793Z2GC5LqVTyFxBdE/xZs41DKzoC4OLJjoiIrCSY2zd753BRTHZERFIg8XN2vKhcghQKBRYvXgyFQuHsUMjN8WeNrhcygetbiYjcVl1dHVQqFRJ6zYWXh31/dLSZDSg88wpqa2td7hws25hERFLANiYREZF7Y2VHRCQFAhxQ2TkkEqdgsiMikgK2MUlKXn75ZYSFhcHHxwfR0dH45JNPnB0SuaGPP/4YkydPhlarhUwmw86dO50dEkkck52EbN++HWlpacjIyEBpaSluvfVWTJw4EadPn3Z2aORmGhsbMWLECOTm5jo7FLrIbHbM5qJ46YGExMbG4sYbb8TatWvFfUOGDMG0adOQnZ3txMjInclkMuTn52PatGnODkWSxEsPeqTAy0Nu11xtZiMKz21wyUsPWNlJhNFoRElJCZKSkiz2JyUlYd++fU6Kiojo2uACFYk4f/48TCYT1Gq1xX61Wg29Xu+kqIjompH4AhUmO4m59FFIgiDw8UhEUiDxR/ywjSkRISEh8PT07FDFVVdXd6j2iIjcDZOdRMjlckRHR6OgoMBif0FBAcaMGeOkqIjoWhEEs0M2V8U2poQsWLAA9913H2JiYjB69GisW7cOp0+fxty5c50dGrmZhoYGfP/99+Lr8vJyHDx4EEFBQejTp48TI5MwQbC/DclzduQK7r77bvz444949tlnUVVVhYiICOzatQt9+/Z1dmjkZg4cOIDbb79dfL1gwQIAQHJyMjZt2uSkqEjKeJ0dEZEbu3id3XjVffCS2XmdnWDE+7WbXfI6O1Z2RERSYDYDMjvPubnwOTsuUCEiIrfHyo6ISAoEB1xn58JnvZjsiIgkQDCbIdjZxnTlSw/YxiQiIrfHyo6ISArYxiQiIrdnFgCZdJMd25hERNQlrvTEekEQkJmZCa1WC19fX8THx6OsrMxijMFgwPz58xESEgJ/f39MmTIFlZWVNsfCZEduIzMzEyNHjhRfz5492ykPDD158iRkMhkOHjzY6Zh+/fohJyfH6jk3bdqE7t272x3b5X7hkEQIQvt1cnZttlV2V3pi/fLly7Fy5Urk5uaiuLgYGo0GiYmJqK+vF8ekpaUhPz8f27Ztw969e9HQ0IBJkybBZDLZFAuTHXWp2bNnQyaTQSaTwdvbG/3798eiRYvQ2NjY5Z/94osvWn1rKmsSFJErE8yCQzZbTJw4EUuXLsX06dM7xiMIyMnJQUZGBqZPn46IiAjk5eWhqakJW7duBQDU1tZiw4YNWLFiBRISEhAVFYUtW7bg0KFDKCwstCkWJjvqcnfccQeqqqpw4sQJLF26FC+//DIWLVp02bGtra0O+1yVSuWQaoiILNXV1VlsBoPB5jnKy8uh1+uRlJQk7lMoFIiLi8O+ffsAACUlJWhtbbUYo9VqERERIY6xFpMddTmFQgGNRgOdToeZM2di1qxZYivtYuvxn//8J/r37w+FQgFBEFBbW4tHHnkEoaGhUCqVGDduHL766iuLeZ977jmo1WoEBAQgJSUFLS0tFu9f2sY0m814/vnnMXDgQCgUCvTp0wfLli0DAISFhQEAoqKiIJPJEB8fLx63ceNGDBkyBD4+Phg8eDBefvlli8/54osvEBUVBR8fH8TExKC0tNTm79HKlSsRGRkJf39/6HQ6pKamoqGhocO4nTt3YtCgQfDx8UFiYiIqKios3n/nnXcQHR0NHx8f9O/fH8888wza2tpsjofckN0tTLN4uzCdTgeVSiVu2dnZNodz8dmalz5PU61Wi+/p9XrI5XIEBgZ2OsZaXI1J15yvr69FBff999/jzTffxI4dO+Dp6QkAuPPOOxEUFIRdu3ZBpVLh1Vdfxfjx4/Htt98iKCgIb775JhYvXoyXXnoJt956KzZv3ozVq1ejf//+nX7uU089hfXr12PVqlW45ZZbUFVVhW+++QZAe8K66aabUFhYiGHDhkEub79h7vr167F48WLk5uYiKioKpaWlePjhh+Hv74/k5GQ0NjZi0qRJGDduHLZs2YLy8nI88cQTNn9PPDw8sHr1avTr1w/l5eVITU1Fenq6RWJtamrCsmXLkJeXB7lcjtTUVNxzzz349NNPAQDvvfce7r33XqxevRq33norjh8/jkceeQQAsHjxYptjIvcimAUIdq7GvPjcgIqKCosbQSsUiqueUyaTdfiMS/ddLo4rjbkUkx1dU1988QW2bt2K8ePHi/uMRiM2b96MHj16AAA++OADHDp0CNXV1eL/RC+88AJ27tyJf/3rX3jkkUeQk5ODBx98EA899BAAYOnSpSgsLOxQ3V1UX1+PF198Ebm5uUhOTgYADBgwALfccgsAiJ8dHBwMjUYjHrdkyRKsWLFCPOcQFhaGI0eO4NVXX0VycjJef/11mEwm/POf/4Sfnx+GDRuGyspKPProozZ9X9LS0sR/DwsLw5IlS/Doo49aJLvW1lbk5uYiNjYWAJCXl4chQ4aIiXrZsmX4y1/+In59/fv3x5IlS5Cens5kRw6lVCrtfurBxf/P9Ho9evbsKe6vrq4Wqz2NRgOj0YiamhqL6q66utrmh06zjUld7j//+Q+6desGHx8fjB49GrfddhvWrFkjvt+3b18x2QDtffqGhgYEBwejW7du4lZeXo7jx48DAI4ePYrRo0dbfM6lr3/t6NGjMBgMFkn2Ss6dO4eKigqkpKRYxLF06VKLOEaMGAE/Pz+r4ujMhx9+iMTERPTq1QsBAQG4//778eOPP1os5PHy8kJMTIz4evDgwejevTuOHj0KoP379uyzz1rE+vDDD6OqqgpNTU02x0TupU0woM1s5ybYfm6uM2FhYdBoNCgoKBD3GY1GFBUViYksOjoa3t7eFmOqqqpw+PBhm5MdKzvqcrfffjvWrl0Lb29vaLVaeHt7W7zv7+9v8dpsNqNnz5746KOPOsx1tQtOfH19bT7GbG4/P7F+/XqxmrroYrvVEY+DPHXqFH73u99h7ty5WLJkCYKCgrB3716kpKR0WLBzudbNxX1msxnPPPPMZVe++fj42B0nuSa5XA6NRoO9+l0OmU+j0Yht/iu50hPr09LSkJWVhfDwcISHhyMrKwt+fn6YOXMmgPZFZikpKVi4cCGCg4MRFBSERYsWITIyEgkJCTbFzWRHXc7f3x8DBw60evyNN94IvV4PLy8v9OvX77JjhgwZgv379+P+++8X9+3fv7/TOcPDw+Hr64v3339fbH3+2sX/eX997Y5arUavXr1w4sQJzJo167LzDh06FJs3b0Zzc7OYUH8rjss5cOAA2trasGLFCnh4tDdb3nzzzQ7j2tracODAAdx0000AgGPHjuHChQsYPHgwgPbv27Fjx2z6XpP78/HxQXl5OYxGo0Pmk8vlVv/xdKUn1qenp6O5uRmpqamoqalBbGws9uzZg4CAAPGYVatWwcvLCzNmzEBzczPGjx+PTZs2iX9wWovJjq47CQkJGD16NKZNm4bnn38eN9xwA3744Qfs2rUL06ZNQ0xMDJ544gkkJycjJiYGt9xyC15//XWUlZV1ukDFx8cHf/7zn5Geng65XI6xY8fi3LlzKCsrQ0pKCkJDQ+Hr64vdu3ejd+/e8PHxgUqlQmZmJh5//HEolUpMnDgRBoMBBw4cQE1NDRYsWICZM2ciIyMDKSkp+Otf/4qTJ0/ihRdesOnrHTBgANra2rBmzRpMnjwZn376KV555ZUO47y9vTF//nysXr0a3t7eeOyxx3DzzTeLye/vf/87Jk2aBJ1Oh7vuugseHh74+uuvcejQISxdutT2/xDkNnx8fJxS3cfHx/9m90MmkyEzMxOZmZmdjvHx8cGaNWssTn1cFYGoCyUnJwtTp07t9P3FixcLI0aM6LC/rq5OmD9/vqDVagVvb29Bp9MJs2bNEk6fPi2OWbZsmRASEiJ069ZNSE5OFtLT0y3muvSzTSaTsHTpUqFv376Ct7e30KdPHyErK0t8f/369YJOpxM8PDyEuLg4cf/rr78ujBw5UpDL5UJgYKBw2223Cf/+97/F9z/77DNhxIgRglwuF0aOHCns2LFDACCUlpZ2+nX37dtXWLVqlfh65cqVQs+ePQVfX19hwoQJwmuvvSYAEGpqagRBEISNGzcKKpVK2LFjh9C/f39BLpcL48aNE06ePGkx7+7du4UxY8YIvr6+glKpFG666SZh3bp14vsAhPz8/E7jInJXMkFw4Tt7EhERWYGrMYmIyO0x2RERkdtjsiMiIrfHZEdERG6PyY6IiNwekx0REbk9JjsiInJ7THZEROT2mOyIiMjtMdkREZHbY7IjIiK39/+CbKw9kShJNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('the confusion matrix Random Forest based on the first task is:')\n",
    "fig, _ = plt.subplots(nrows=1, figsize=(5,5))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "ax.grid(False)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix(y_val, y_val_pred, labels=[0,1]), display_labels=[0,1])\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38519211",
   "metadata": {},
   "source": [
    "### 3. Use any hyper parameter tuning method to find the best values lambdas to maximize PerfT1(M ̂ D train1| ̂ D val1 ). Is the optimal value result in  lambda_p = lambda_n = lambda_0? If not what is the ordering of the lambdas , and what can we infer from this ordering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8806f4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_p_list  [0.2 0.4 0.6 0.8 1. ]\n",
      "lambda_n_list  [0.2 0.4 0.6 0.8 1. ]\n",
      "lambda_0_list  [0.2 0.4 0.6 0.8 1. ]\n"
     ]
    }
   ],
   "source": [
    "#List of lamdas generated to try different combinations as part of hyperparameter tuning between 0.2 to 1\n",
    "\n",
    "lambda_p_list = np.arange(0.2, 1.1, 0.2)\n",
    "print(\"lambda_p_list \",lambda_p_list)\n",
    "lambda_n_list = np.arange(0.2, 1.1, 0.2)\n",
    "print(\"lambda_n_list \",lambda_n_list)\n",
    "lambda_0_list = np.arange(0.2, 1.1, 0.2)\n",
    "print(\"lambda_0_list \",lambda_0_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98036900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda_p: 0.2, Lambda_n: 0.2, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7372072853425845\n",
      "Lambda_p: 0.2, Lambda_n: 0.2, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7334494773519163\n",
      "Lambda_p: 0.2, Lambda_n: 0.2, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7352941176470588\n",
      "Lambda_p: 0.2, Lambda_n: 0.2, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7334494773519163\n",
      "Lambda_p: 0.2, Lambda_n: 0.2, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7236268526591109\n",
      "Lambda_p: 0.2, Lambda_n: 0.4, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7272727272727272\n",
      "Lambda_p: 0.2, Lambda_n: 0.4, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7396551724137931\n",
      "Lambda_p: 0.2, Lambda_n: 0.4, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7234416154521511\n",
      "Lambda_p: 0.2, Lambda_n: 0.4, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7226596675415574\n",
      "Lambda_p: 0.2, Lambda_n: 0.4, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7275892080069625\n",
      "Lambda_p: 0.2, Lambda_n: 0.6000000000000001, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7383015597920277\n",
      "Lambda_p: 0.2, Lambda_n: 0.6000000000000001, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7225130890052356\n",
      "Lambda_p: 0.2, Lambda_n: 0.6000000000000001, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7263157894736841\n",
      "Lambda_p: 0.2, Lambda_n: 0.6000000000000001, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7333333333333333\n",
      "Lambda_p: 0.2, Lambda_n: 0.6000000000000001, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7362924281984334\n",
      "Lambda_p: 0.2, Lambda_n: 0.8, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7234416154521511\n",
      "Lambda_p: 0.2, Lambda_n: 0.8, Lambda_0: 0.4, Task 1 Validation f1_score: 0.735930735930736\n",
      "Lambda_p: 0.2, Lambda_n: 0.8, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7326906222611743\n",
      "Lambda_p: 0.2, Lambda_n: 0.8, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7275892080069625\n",
      "Lambda_p: 0.2, Lambda_n: 0.8, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7362924281984334\n",
      "Lambda_p: 0.2, Lambda_n: 1.0, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7211961301671065\n",
      "Lambda_p: 0.2, Lambda_n: 1.0, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7261592300962381\n",
      "Lambda_p: 0.2, Lambda_n: 1.0, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7309377738825591\n",
      "Lambda_p: 0.2, Lambda_n: 1.0, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7290209790209791\n",
      "Lambda_p: 0.2, Lambda_n: 1.0, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7312390924956369\n",
      "Lambda_p: 0.4, Lambda_n: 0.2, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7320034692107545\n",
      "Lambda_p: 0.4, Lambda_n: 0.2, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7234782608695651\n",
      "Lambda_p: 0.4, Lambda_n: 0.2, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7312013828867762\n",
      "Lambda_p: 0.4, Lambda_n: 0.2, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7263249348392702\n",
      "Lambda_p: 0.4, Lambda_n: 0.2, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7301310043668122\n",
      "Lambda_p: 0.4, Lambda_n: 0.4, Lambda_0: 0.2, Task 1 Validation f1_score: 0.735191637630662\n",
      "Lambda_p: 0.4, Lambda_n: 0.4, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7372072853425845\n",
      "Lambda_p: 0.4, Lambda_n: 0.4, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7312013828867762\n",
      "Lambda_p: 0.4, Lambda_n: 0.4, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7334494773519163\n",
      "Lambda_p: 0.4, Lambda_n: 0.4, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7248908296943232\n",
      "Lambda_p: 0.4, Lambda_n: 0.6000000000000001, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7271142109851787\n",
      "Lambda_p: 0.4, Lambda_n: 0.6000000000000001, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7351164797238999\n",
      "Lambda_p: 0.4, Lambda_n: 0.6000000000000001, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7335640138408305\n",
      "Lambda_p: 0.4, Lambda_n: 0.6000000000000001, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7275922671353251\n",
      "Lambda_p: 0.4, Lambda_n: 0.6000000000000001, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7272727272727272\n",
      "Lambda_p: 0.4, Lambda_n: 0.8, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7290209790209791\n",
      "Lambda_p: 0.4, Lambda_n: 0.8, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7272727272727272\n",
      "Lambda_p: 0.4, Lambda_n: 0.8, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7336244541484715\n",
      "Lambda_p: 0.4, Lambda_n: 0.8, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7396551724137931\n",
      "Lambda_p: 0.4, Lambda_n: 0.8, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7260034904013961\n",
      "Lambda_p: 0.4, Lambda_n: 1.0, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7328646748681897\n",
      "Lambda_p: 0.4, Lambda_n: 1.0, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7283842794759826\n",
      "Lambda_p: 0.4, Lambda_n: 1.0, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7283842794759826\n",
      "Lambda_p: 0.4, Lambda_n: 1.0, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7304347826086957\n",
      "Lambda_p: 0.4, Lambda_n: 1.0, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7393199651264167\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.2, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7321739130434782\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.2, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7227036395147313\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.2, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7305699481865285\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.2, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7248908296943232\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.2, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7264808362369338\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.4, Lambda_0: 0.2, Task 1 Validation f1_score: 0.731537793223284\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.4, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7320034692107545\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.4, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7361111111111112\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.4, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7323452484742806\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.4, Lambda_0: 1.0, Task 1 Validation f1_score: 0.731408573928259\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.6000000000000001, Lambda_0: 0.2, Task 1 Validation f1_score: 0.736196319018405\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.6000000000000001, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7264808362369338\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.6000000000000001, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7329299913569576\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.6000000000000001, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7218831734960767\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.6000000000000001, Lambda_0: 1.0, Task 1 Validation f1_score: 0.735930735930736\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.8, Lambda_0: 0.2, Task 1 Validation f1_score: 0.723292469352014\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.8, Lambda_0: 0.4, Task 1 Validation f1_score: 0.731665228645384\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.8, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7280625543006081\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.8, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7335640138408305\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 0.8, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7310704960835509\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 1.0, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7275922671353251\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 1.0, Lambda_0: 0.4, Task 1 Validation f1_score: 0.733800350262697\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 1.0, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7342657342657342\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 1.0, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7304347826086957\n",
      "Lambda_p: 0.6000000000000001, Lambda_n: 1.0, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7288578901482127\n",
      "Lambda_p: 0.8, Lambda_n: 0.2, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7340241796200345\n",
      "Lambda_p: 0.8, Lambda_n: 0.2, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7297762478485369\n",
      "Lambda_p: 0.8, Lambda_n: 0.2, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7180385288966725\n",
      "Lambda_p: 0.8, Lambda_n: 0.2, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7340241796200345\n",
      "Lambda_p: 0.8, Lambda_n: 0.2, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7271142109851787\n",
      "Lambda_p: 0.8, Lambda_n: 0.4, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7310704960835509\n",
      "Lambda_p: 0.8, Lambda_n: 0.4, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7320034692107545\n",
      "Lambda_p: 0.8, Lambda_n: 0.4, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7376623376623377\n",
      "Lambda_p: 0.8, Lambda_n: 0.4, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7234782608695651\n",
      "Lambda_p: 0.8, Lambda_n: 0.4, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7294938917975567\n",
      "Lambda_p: 0.8, Lambda_n: 0.6000000000000001, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7253705318221446\n",
      "Lambda_p: 0.8, Lambda_n: 0.6000000000000001, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7269534679543459\n",
      "Lambda_p: 0.8, Lambda_n: 0.6000000000000001, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7339130434782609\n",
      "Lambda_p: 0.8, Lambda_n: 0.6000000000000001, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7225130890052356\n",
      "Lambda_p: 0.8, Lambda_n: 0.6000000000000001, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7261698440207972\n",
      "Lambda_p: 0.8, Lambda_n: 0.8, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7261592300962381\n",
      "Lambda_p: 0.8, Lambda_n: 0.8, Lambda_0: 0.4, Task 1 Validation f1_score: 0.735191637630662\n",
      "Lambda_p: 0.8, Lambda_n: 0.8, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7365684575389948\n",
      "Lambda_p: 0.8, Lambda_n: 0.8, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7372072853425845\n",
      "Lambda_p: 0.8, Lambda_n: 0.8, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7282229965156795\n",
      "Lambda_p: 0.8, Lambda_n: 1.0, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7296587926509186\n",
      "Lambda_p: 0.8, Lambda_n: 1.0, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7329842931937173\n",
      "Lambda_p: 0.8, Lambda_n: 1.0, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7445887445887446\n",
      "Lambda_p: 0.8, Lambda_n: 1.0, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7288578901482127\n",
      "Lambda_p: 0.8, Lambda_n: 1.0, Lambda_0: 1.0, Task 1 Validation f1_score: 0.734835355285962\n",
      "Lambda_p: 1.0, Lambda_n: 0.2, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7253705318221446\n",
      "Lambda_p: 1.0, Lambda_n: 0.2, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7288578901482127\n",
      "Lambda_p: 1.0, Lambda_n: 0.2, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7307359307359307\n",
      "Lambda_p: 1.0, Lambda_n: 0.2, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7294727744165947\n",
      "Lambda_p: 1.0, Lambda_n: 0.2, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7266375545851528\n",
      "Lambda_p: 1.0, Lambda_n: 0.4, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7288428324697755\n",
      "Lambda_p: 1.0, Lambda_n: 0.4, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7307692307692308\n",
      "Lambda_p: 1.0, Lambda_n: 0.4, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7271142109851787\n",
      "Lambda_p: 1.0, Lambda_n: 0.4, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7183958151700087\n",
      "Lambda_p: 1.0, Lambda_n: 0.4, Lambda_0: 1.0, Task 1 Validation f1_score: 0.720626631853786\n",
      "Lambda_p: 1.0, Lambda_n: 0.6000000000000001, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7340889276373147\n",
      "Lambda_p: 1.0, Lambda_n: 0.6000000000000001, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7298245614035088\n",
      "Lambda_p: 1.0, Lambda_n: 0.6000000000000001, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7376623376623377\n",
      "Lambda_p: 1.0, Lambda_n: 0.6000000000000001, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7291849255039438\n",
      "Lambda_p: 1.0, Lambda_n: 0.6000000000000001, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7310704960835509\n",
      "Lambda_p: 1.0, Lambda_n: 0.8, Lambda_0: 0.2, Task 1 Validation f1_score: 0.732638888888889\n",
      "Lambda_p: 1.0, Lambda_n: 0.8, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7237762237762237\n",
      "Lambda_p: 1.0, Lambda_n: 0.8, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7349397590361445\n",
      "Lambda_p: 1.0, Lambda_n: 0.8, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7324675324675324\n",
      "Lambda_p: 1.0, Lambda_n: 0.8, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7244094488188976\n",
      "Lambda_p: 1.0, Lambda_n: 1.0, Lambda_0: 0.2, Task 1 Validation f1_score: 0.7266375545851528\n",
      "Lambda_p: 1.0, Lambda_n: 1.0, Lambda_0: 0.4, Task 1 Validation f1_score: 0.7299396031061259\n",
      "Lambda_p: 1.0, Lambda_n: 1.0, Lambda_0: 0.6000000000000001, Task 1 Validation f1_score: 0.7223672758920799\n",
      "Lambda_p: 1.0, Lambda_n: 1.0, Lambda_0: 0.8, Task 1 Validation f1_score: 0.7269565217391305\n",
      "Lambda_p: 1.0, Lambda_n: 1.0, Lambda_0: 1.0, Task 1 Validation f1_score: 0.7335640138408305\n"
     ]
    }
   ],
   "source": [
    "best_lambda_p = None\n",
    "best_lambda_n = None\n",
    "best_lambda_0 = None\n",
    "best_perf_t1_RF = 0\n",
    "\n",
    "for lambda_p in lambda_p_list:\n",
    "\n",
    "    for lambda_n in lambda_n_list:\n",
    "        \n",
    "        for lambda_0 in lambda_0_list:\n",
    "            \n",
    "            sample_weights_label2 = np.where(train_label_2 == 2, lambda_p,\n",
    "                          np.where(train_label_2 == 0, lambda_n,\n",
    "                          lambda_0))\n",
    "            # fit the model using sample weights\n",
    "            model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state = 0)\n",
    "            model.fit(X_train, y_train, sample_weight = sample_weights_label2)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "            perf_t1_RF = f1_score(y_val, y_val_pred)\n",
    "            \n",
    "            print(f\"Lambda_p: {lambda_p}, Lambda_n: {lambda_n}, Lambda_0: {lambda_0}, Task 1 Validation f1_score: {perf_t1_RF}\")\n",
    "            \n",
    "            if perf_t1_RF > best_perf_t1_RF:\n",
    "                best_perf_t1_RF = perf_t1_RF\n",
    "                best_lambda_p = lambda_p\n",
    "                best_lambda_n = lambda_n\n",
    "                best_lambda_0 = lambda_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d25f9741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7445887445887446"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best F1-Score on validation data\n",
    "best_perf_t1_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5575029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Weights for postive samples\n",
    "best_lambda_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "060c4f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Weights for negative samples\n",
    "best_lambda_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "633b859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6000000000000001"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best Weights for neutral samples\n",
    "best_lambda_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a1243f",
   "metadata": {},
   "source": [
    "The optimal values does not result in best_lambda_p = best_lambda_n = best_lambda_0.\n",
    "\n",
    "lambda_p = 0.8\n",
    "lambda_n = 1.0\n",
    "lambda_0 = 0.6\n",
    "\n",
    "#### best_lambda_n > best_lambda_p > best_lambda_0\n",
    "\n",
    "\n",
    "This indicates that the model is encouraged to rely more heavily on Negative sentiment data samples when compared to positive and neutral data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6528bac-4a3a-4437-a35f-e57a3db04e6f",
   "metadata": {},
   "source": [
    "The model is then retrained using the optimal lambdas and used to predict on the test dataset. The results of the prediction are then submitted in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cea65558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using best Lamba values we got from grid search\n",
    "\n",
    "#Sentiment Label Weights\n",
    "lambda_p = 0.8\n",
    "lambda_n = 1.0\n",
    "lambda_0 = 0.6\n",
    "\n",
    "\n",
    "sample_weights_label2 = np.where(train_label_2 == 2, lambda_p,\n",
    "                          np.where(train_label_2 == 0, lambda_n,\n",
    "                          lambda_0))\n",
    "\n",
    "# create a Random Forest model with sample weights\n",
    "model = RandomForestClassifier(n_estimators=100, criterion='entropy', random_state = 0)\n",
    "\n",
    "# fit the model using sample weights\n",
    "model.fit(X_train, y_train, sample_weight = sample_weights_label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95add3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of Random Forest based on the first task is 0.7334494773519163\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "perf_t1_RF = f1_score(y_val, y_val_pred)\n",
    "print(f'The f1 score of Random Forest based on the first task is {perf_t1_RF}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8b573f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.vstack(df_d1_test['sentence_embeddings'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f95e6f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d5080c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'id': df_d1_test.id,\n",
    "                       'target': y_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "366c7234",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6483ac97",
   "metadata": {},
   "source": [
    "### The model resulted in Score of 79.16% in Kaggle.(Please refer screenshot in the zip file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ecdb90-2271-4a4b-a769-ec8efcfce42e",
   "metadata": {},
   "source": [
    "# V. Further Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29231080-8e91-4f5d-a65c-ed3bec2e4a4b",
   "metadata": {},
   "source": [
    "## 1. Soft-Parameter Sharing Multi-Task Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2957c7ad-a4ba-4e4d-b928-22ba488a4b53",
   "metadata": {},
   "source": [
    "Similar to the hard parameter sharing MTL model shown in section 5, a soft-parameter sharing MTL model was explored. A simple schematic of the soft parameter sharing model is shown below."
   ]
  },
  {
   "attachments": {
    "bdacbc2e-2c78-4a54-ab13-7ff230c250fd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "53038606-4d17-4ace-8547-c21a91fd76bd",
   "metadata": {},
   "source": [
    "![softparameter.png](attachment:bdacbc2e-2c78-4a54-ab13-7ff230c250fd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7dba5e-64d6-4ba5-8b8a-c70fdd896714",
   "metadata": {},
   "source": [
    "In this model, instead of both tasks sharing the hidden layers and the same weights, each task has its own model and hidden layers. However, the weights of the hidden layers are regularised to train the weights to be similar but not the same (as in hard parameter sharing MTL model). This may give some flexibility in the model to learn specific components of each tasks even though the weights are similar for both tasks.\n",
    "\n",
    "For this MTL model, two models (with the same architecture) are trained separately with its own loss function and optimiser for each task. However, each loss function for each task has a regularisation term which takes into account the difference in weights of the hidden layers between the two tasks models. This is to train both models to have similar weights in their hidden layers. A hyperparameter lambda is used to test the magnitude of the regularisation term that is needed to give the best results based on the requirements.\n",
    "\n",
    "For our case, since the primary task is task 1, we would like to hyper parameter tune the lambda to give the best performance for task 1 based on the validation set. \n",
    "The performance of the model for task1 using lambda=0.1 based on the validation dataset is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "83779f2c-53f3-4311-9734-0e5805e3e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Soft parameter sharing model\n",
    "class NeuralNetworkTask1(nn.Module):\n",
    "    \n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(768, 1024)\n",
    "        self.lin2 = nn.Linear(1024, 512)\n",
    "        self.lin3 = nn.Linear(512, 128)\n",
    "        self.lin4 = nn.Linear(128, n_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin4(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class NeuralNetworkTask2(nn.Module):\n",
    " \n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(768, 1024)\n",
    "        self.lin2 = nn.Linear(1024, 512)\n",
    "        self.lin3 = nn.Linear(512, 128)\n",
    "        self.lin4 = nn.Linear(128, n_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "21c39094-184c-4674-815f-764119e9eff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Loss Task1 - 1.7796974171436728, Loss Task2 - 2.4929786027156684\n",
      "Epoch 2/20: Loss Task1 - 0.14330778666400693, Loss Task2 - 0.7699569803164055\n",
      "Epoch 3/20: Loss Task1 - 0.13460774347186089, Loss Task2 - 0.7224347383666418\n",
      "Epoch 4/20: Loss Task1 - 0.131738688542183, Loss Task2 - 0.7041303356579062\n",
      "Epoch 5/20: Loss Task1 - 0.12957237476741806, Loss Task2 - 0.6879893787086417\n",
      "Epoch 6/20: Loss Task1 - 0.12726653213686986, Loss Task2 - 0.6800424119877653\n",
      "Epoch 7/20: Loss Task1 - 0.1265561264390147, Loss Task2 - 0.6731941377519204\n",
      "Epoch 8/20: Loss Task1 - 0.12478403531541042, Loss Task2 - 0.6670736719372604\n",
      "Epoch 9/20: Loss Task1 - 0.12249534221573952, Loss Task2 - 0.6603916436773226\n",
      "Epoch 10/20: Loss Task1 - 0.12183544721988991, Loss Task2 - 0.6565559153404757\n",
      "Epoch 11/20: Loss Task1 - 0.11973598970265757, Loss Task2 - 0.6499168625046289\n",
      "Epoch 12/20: Loss Task1 - 0.12081223423327564, Loss Task2 - 0.6459251269528425\n",
      "Epoch 13/20: Loss Task1 - 0.11901708351180874, Loss Task2 - 0.6396629025561391\n",
      "Epoch 14/20: Loss Task1 - 0.11790724054555958, Loss Task2 - 0.6369388385894358\n",
      "Epoch 15/20: Loss Task1 - 0.11725888773798943, Loss Task2 - 0.633535653556398\n",
      "Epoch 16/20: Loss Task1 - 0.11591038499494212, Loss Task2 - 0.6286621890062624\n",
      "Epoch 17/20: Loss Task1 - 0.11453722890016702, Loss Task2 - 0.6245511800118623\n",
      "Epoch 18/20: Loss Task1 - 0.11403365630512222, Loss Task2 - 0.6189189012881564\n",
      "Epoch 19/20: Loss Task1 - 0.11320259998253375, Loss Task2 - 0.6125335980520704\n",
      "Epoch 20/20: Loss Task1 - 0.11106275994084555, Loss Task2 - 0.6109236001561063\n"
     ]
    }
   ],
   "source": [
    "# Training the softparameter sharing model for lambda = 0.1\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "network1 = NeuralNetworkTask1(2)\n",
    "network2 = NeuralNetworkTask2(3)\n",
    "\n",
    "# Define the loss functions\n",
    "criterion_task1 = torch.nn.CrossEntropyLoss()\n",
    "criterion_task2 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizers\n",
    "optimizer1 = torch.optim.Adam(network1.parameters(), lr=0.0001)\n",
    "optimizer2 = torch.optim.Adam(network2.parameters(), lr=0.0001)\n",
    "\n",
    "# Hyperparameter for controlling the weight similarity\n",
    "lambda_value = 0.1\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    l1 = 0\n",
    "    l2 = 0\n",
    "    num_batches = 0\n",
    "    for (inputs, labels_task1, labels_task2) in D12_train_dataloader:\n",
    "\n",
    "        idx1 = labels_task1 != np.nan\n",
    "        idx2 = labels_task2 != np.nan\n",
    "        input1 = inputs[idx1]\n",
    "        input2 = inputs[idx2] \n",
    "\n",
    "        #optimizer2.zero_grad()\n",
    "        # Forward pass for both tasks\n",
    "        outputs_task1 = network1(input1)\n",
    "        outputs_task2 = network2(input2)\n",
    "\n",
    "        # Calculate the losses for both tasks\n",
    "        loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "        loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "        # Calculate the regularization term\n",
    "        regularization_term = (\n",
    "            torch.norm(network1.lin1.weight - network2.lin1.weight, 2) +\n",
    "            torch.norm(network1.lin2.weight - network2.lin2.weight, 2) +\n",
    "            torch.norm(network1.lin3.weight - network2.lin3.weight, 2)\n",
    "        )\n",
    "\n",
    "        # Add the regularization term to the losses\n",
    "        total_loss_task1 = loss_task1 + + lambda_value * regularization_term\n",
    "        total_loss_task2 = loss_task2 + lambda_value * regularization_term\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_loss_task1.backward(retain_graph=True)\n",
    "        total_loss_task2.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        l1 += total_loss_task1.detach().item()\n",
    "        l2 += total_loss_task2.detach().item()\n",
    "        \n",
    "        num_batches += 1\n",
    "    # Print the losses for the current epoch\n",
    "   # print(f\"Epoch {epoch + 1}/{n_epochs}: Loss Task1 - {loss_task1.item():.4f}, Loss Task2 - {loss_task2.item():.4f}\")\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}: Loss Task1 - {l1/num_batches}, Loss Task2 - {l2/num_batches}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "id": "c5ddb134-899b-4fcc-ad73-d53e751b11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation of softparameter model with lambda = 0.1\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "truth1 = []\n",
    "truth2 = []\n",
    "class_probs_t1 = []\n",
    "class_probs_t2 = []\n",
    "class_preds_t1 = []\n",
    "class_preds_t2 = []\n",
    "with torch.no_grad():\n",
    "    for data in D1_hat_val_dataloader:\n",
    "        x, y1, y2 = data\n",
    "        output_t1 = network1(x)\n",
    "        output_t2 = network2(x)\n",
    "\n",
    "        class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "        class_probs_t2_batch = [nn.Softmax(dim=0)(el) for el in output_t2]\n",
    "\n",
    "        _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "        _, class_preds_t2_batch = torch.max(output_t2, 1)\n",
    "\n",
    "        class_probs_t1.append(class_probs_t1_batch)\n",
    "        class_probs_t2.append(class_probs_t2_batch)\n",
    "\n",
    "        class_preds_t1.append(class_preds_t1_batch)\n",
    "        class_preds_t2.append(class_preds_t2_batch)\n",
    "        \n",
    "        truth1.extend([l.item() for l in y1])\n",
    "        truth2.extend([l.item() for l in y2])\n",
    "\n",
    "val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "val_probs_t2 = torch.cat([torch.stack(batch) for batch in class_probs_t2])\n",
    "val_preds_t1 = torch.cat(class_preds_t1)\n",
    "val_preds_t2 = torch.cat(class_preds_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "fe0aafde-e7c2-4417-9122-d5971139c704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of soft parameter sharing model based on the first task is 0.7550854353132629\n"
     ]
    }
   ],
   "source": [
    "perf_t1_network1 = f1_score(truth1, val_preds_t1)\n",
    "print(f'The f1 score of soft parameter sharing model based on the first task is {perf_t1_network1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b1a3bf-005d-432e-8534-4a293a501cd1",
   "metadata": {},
   "source": [
    "Ranging lambda from 0 to 1, the best hyperparameter was found by gridsearch to give the best performance for task 1 using this MTL model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "3df01a3e-0ae4-4ff4-895b-53e37f9d2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train and evaluate model for each lambda for soft parameter sharing model\n",
    "def train_and_evaluate_model_1(network1, network2, lambda_value, train_dataloader, val_dataloader):\n",
    "\n",
    "\n",
    "    epochs = 20\n",
    "\n",
    "    # Define separate loss functions for each task\n",
    "    criterion_task1 = nn.CrossEntropyLoss()\n",
    "    criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer1 = torch.optim.Adam(network1.parameters(), lr=0.0001)\n",
    "    optimizer2 = torch.optim.Adam(network2.parameters(), lr=0.0001)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        l1 = 0\n",
    "        l2 = 0\n",
    "        for (inputs, labels_task1, labels_task2) in train_dataloader:\n",
    "            \n",
    "            idx1 = labels_task1 != np.nan\n",
    "            idx2 = labels_task2 != np.nan\n",
    "            input1 = inputs[idx1]\n",
    "            input2 = inputs[idx2] \n",
    "            \n",
    "            # Forward pass\n",
    "            outputs_task1 = network1(input1)\n",
    "            outputs_task2 = network2(input2)\n",
    "\n",
    "            # Compute the losses for each task\n",
    "            loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "            loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "            \n",
    "            # Calculate the regularization term\n",
    "            regularization_term = (\n",
    "                torch.norm(network1.lin1.weight - network2.lin1.weight, 2) +\n",
    "                torch.norm(network1.lin2.weight - network2.lin2.weight, 2) +\n",
    "                torch.norm(network1.lin3.weight - network2.lin3.weight, 2)\n",
    "            )\n",
    "            \n",
    "            #Add the regularization term to the losses\n",
    "            total_loss_task1 = loss_task1 + lambda_value * regularization_term\n",
    "            total_loss_task2 = loss_task2 + lambda_value * regularization_term\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            total_loss_task1.backward(retain_graph = True)\n",
    "            total_loss_task2.backward()\n",
    "            optimizer1.step()\n",
    "            optimizer2.step()\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer1.zero_grad()\n",
    "            optimizer2.zero_grad()\n",
    "\n",
    "            # Accumulate the running loss\n",
    "            l1 += total_loss_task1.detach().item()\n",
    "            l2 += total_loss_task2.detach().item()\n",
    "        #print(f\"Epoch {epoch}: Training loss: {l1/num_batches}\")\n",
    "\n",
    "\n",
    "    #Evalution of model for task 1\n",
    "    \n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  \n",
    "    \n",
    "    truth1 = []\n",
    "    truth2 = []\n",
    "    class_probs_t1 = []\n",
    "    class_probs_t2 = []\n",
    "    class_preds_t1 = []\n",
    "    class_preds_t2 = []\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            x, y1, y2 = data\n",
    "            output_t1 = network1(x)\n",
    "            output_t2 = network2(x)\n",
    "\n",
    "            class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "            class_probs_t2_batch = [nn.Softmax(dim=0)(el) for el in output_t2]\n",
    "\n",
    "            _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "            _, class_preds_t2_batch = torch.max(output_t2, 1)\n",
    "\n",
    "            class_probs_t1.append(class_probs_t1_batch)\n",
    "            class_probs_t2.append(class_probs_t2_batch)\n",
    "\n",
    "            class_preds_t1.append(class_preds_t1_batch)\n",
    "            class_preds_t2.append(class_preds_t2_batch)\n",
    "\n",
    "            truth1.extend([l.item() for l in y1])\n",
    "            truth2.extend([l.item() for l in y2])\n",
    "\n",
    "    val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "    val_probs_t2 = torch.cat([torch.stack(batch) for batch in class_probs_t2])\n",
    "    val_preds_t1 = torch.cat(class_preds_t1)\n",
    "    val_preds_t2 = torch.cat(class_preds_t2) \n",
    "\n",
    "    perf_t1_network1 = f1_score(truth1, val_preds_t1)   \n",
    "    perf_t2_network2 = accuracy_score(truth2, val_preds_t2)\n",
    "\n",
    "    return perf_t1_network1, perf_t2_network2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "92e68716-0b1d-46a3-8830-79d833befd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda_1: 0, Task 1 Validation f1_score: 0.7572493786246894, Task 2 Validation accuracy score: 0.41365725541694026\n",
      "Lambda_1: 0.1, Task 1 Validation f1_score: 0.7550854353132629, Task 2 Validation accuracy score: 0.42547603414313856\n",
      "Lambda_1: 0.2, Task 1 Validation f1_score: 0.7567567567567567, Task 2 Validation accuracy score: 0.42350623768877216\n",
      "Lambda_1: 0.3, Task 1 Validation f1_score: 0.7574750830564784, Task 2 Validation accuracy score: 0.41365725541694026\n",
      "Lambda_1: 0.4, Task 1 Validation f1_score: 0.7502102607232969, Task 2 Validation accuracy score: 0.41628365068942874\n",
      "Lambda_1: 0.5, Task 1 Validation f1_score: 0.7415540540540541, Task 2 Validation accuracy score: 0.4169402495075509\n",
      "Lambda_1: 0.6, Task 1 Validation f1_score: 0.7438715131022825, Task 2 Validation accuracy score: 0.4143138542350624\n",
      "Lambda_1: 0.7, Task 1 Validation f1_score: 0.7408666100254886, Task 2 Validation accuracy score: 0.412344057780696\n",
      "Lambda_1: 0.8, Task 1 Validation f1_score: 0.7342419080068143, Task 2 Validation accuracy score: 0.41365725541694026\n",
      "Lambda_1: 0.9, Task 1 Validation f1_score: 0.7336170212765958, Task 2 Validation accuracy score: 0.4143138542350624\n",
      "Lambda_1: 1.0, Task 1 Validation f1_score: 0.7351443123938879, Task 2 Validation accuracy score: 0.41365725541694026\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch to find optimal lambda for obtaining best task 1 performance on \n",
    "# soft parameter sharing model\n",
    "\n",
    "lambda_list = [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0] \n",
    "\n",
    "best_lambda_value = None\n",
    "best_t1_val_perf = 0\n",
    "\n",
    "## Run all value lambda to find best combination for best \n",
    "## T1 performance\n",
    "for lambda_value in lambda_list:\n",
    "\n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    network1 = NeuralNetworkTask1(2)\n",
    "    network2 = NeuralNetworkTask2(3)\n",
    "\n",
    "    task1_val_perf, task2_val_perf = train_and_evaluate_model_1(network1, network2, lambda_value, D12_train_dataloader, D1_hat_val_dataloader)\n",
    "\n",
    "    print(f\"Lambda_1: {lambda_value}, Task 1 Validation f1_score: {task1_val_perf}, Task 2 Validation accuracy score: {task2_val_perf}\")\n",
    "\n",
    "    if task1_val_perf > best_t1_val_perf:\n",
    "        best_t1_val_perf = task1_val_perf\n",
    "        best_lambda_value = lambda_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9433320-6f2e-40b9-a69f-161428a5710c",
   "metadata": {},
   "source": [
    "The best hyperparameter lambda found is 0.3 which gives the best performance for task 1 on the validation dataset. The performance of the model is also better for task 1 compared to the model trained only on D1 dataset in Section 1.\n",
    "This lambda was used to re-train the MTL model. The re-trained optimised for task 1 model is then used to predict the labels for the D1 test dataset to be submitted in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "f98ccbc6-b2f3-40af-9362-e39cd6730418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda value is: 0.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best lambda value is: {best_lambda_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "dc2db2eb-493d-472c-8726-76c124208ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Loss Task1 - 4.496460336691155, Loss Task2 - 5.2398159551457555\n",
      "Epoch 2/20: Loss Task1 - 0.1452056981606201, Loss Task2 - 0.8099053932485385\n",
      "Epoch 3/20: Loss Task1 - 0.13970392224100972, Loss Task2 - 0.7702124413433814\n",
      "Epoch 4/20: Loss Task1 - 0.1379690540101642, Loss Task2 - 0.7431152191411933\n",
      "Epoch 5/20: Loss Task1 - 0.1360116025564475, Loss Task2 - 0.7203681880357868\n",
      "Epoch 6/20: Loss Task1 - 0.13328767089270785, Loss Task2 - 0.7067200947459575\n",
      "Epoch 7/20: Loss Task1 - 0.13306335686092904, Loss Task2 - 0.6977345692948491\n",
      "Epoch 8/20: Loss Task1 - 0.13126218466593084, Loss Task2 - 0.6900853143330316\n",
      "Epoch 9/20: Loss Task1 - 0.12965785343717606, Loss Task2 - 0.6835431127993555\n",
      "Epoch 10/20: Loss Task1 - 0.12749207401245086, Loss Task2 - 0.6770396883639768\n",
      "Epoch 11/20: Loss Task1 - 0.1266310625626856, Loss Task2 - 0.6713851383443845\n",
      "Epoch 12/20: Loss Task1 - 0.12686521229429643, Loss Task2 - 0.6670187370244898\n",
      "Epoch 13/20: Loss Task1 - 0.12689268610234414, Loss Task2 - 0.662609044131494\n",
      "Epoch 14/20: Loss Task1 - 0.12485369863858391, Loss Task2 - 0.6588954001597228\n",
      "Epoch 15/20: Loss Task1 - 0.1252524377459953, Loss Task2 - 0.6553548488910215\n",
      "Epoch 16/20: Loss Task1 - 0.12372131331702843, Loss Task2 - 0.6511126914165558\n",
      "Epoch 17/20: Loss Task1 - 0.12394441575117426, Loss Task2 - 0.64787970452754\n",
      "Epoch 18/20: Loss Task1 - 0.123214137080658, Loss Task2 - 0.6445317939093553\n",
      "Epoch 19/20: Loss Task1 - 0.12308349005521566, Loss Task2 - 0.6373943102658474\n",
      "Epoch 20/20: Loss Task1 - 0.12116744360782562, Loss Task2 - 0.6375527580126543\n"
     ]
    }
   ],
   "source": [
    "#Re-train the model with lambda = 0.3 to be used for prediction of test data\n",
    "\n",
    "# Initialize the networks\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "network1 = NeuralNetworkTask1(2)\n",
    "network2 = NeuralNetworkTask2(3)\n",
    "\n",
    "# Define the loss functions\n",
    "criterion_task1 = torch.nn.CrossEntropyLoss()\n",
    "criterion_task2 = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizers\n",
    "optimizer1 = torch.optim.Adam(network1.parameters(), lr=0.0001)\n",
    "optimizer2 = torch.optim.Adam(network2.parameters(), lr=0.0001)\n",
    "\n",
    "# Hyperparameter for controlling the weight similarity\n",
    "lambda_value = 0.3\n",
    "\n",
    "# Training loop\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    l1 = 0\n",
    "    l2 = 0\n",
    "    num_batches = 0\n",
    "    for (inputs, labels_task1, labels_task2) in D12_train_dataloader:\n",
    "\n",
    "        idx1 = labels_task1 != np.nan\n",
    "        idx2 = labels_task2 != np.nan\n",
    "        input1 = inputs[idx1]\n",
    "        input2 = inputs[idx2] \n",
    "\n",
    "        # Forward pass for both tasks\n",
    "        outputs_task1 = network1(input1)\n",
    "        outputs_task2 = network2(input2)\n",
    "\n",
    "        # Calculate the losses for both tasks\n",
    "        loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "        loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "        # Calculate the regularization term\n",
    "        regularization_term = (\n",
    "            torch.norm(network1.lin1.weight - network2.lin1.weight, 2) +\n",
    "            torch.norm(network1.lin2.weight - network2.lin2.weight, 2) +\n",
    "            torch.norm(network1.lin3.weight - network2.lin3.weight, 2)\n",
    "        )\n",
    "\n",
    "        # Add the regularization term to the losses\n",
    "        total_loss_task1 = loss_task1 + + lambda_value * regularization_term\n",
    "        total_loss_task2 = loss_task2 + lambda_value * regularization_term\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_loss_task1.backward(retain_graph=True)\n",
    "        total_loss_task2.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        l1 += total_loss_task1.detach().item()\n",
    "        l2 += total_loss_task2.detach().item()\n",
    "        \n",
    "        num_batches += 1\n",
    "    # Print the losses for the current epoch\n",
    "   # print(f\"Epoch {epoch + 1}/{n_epochs}: Loss Task1 - {loss_task1.item():.4f}, Loss Task2 - {loss_task2.item():.4f}\")\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}: Loss Task1 - {l1/num_batches}, Loss Task2 - {l2/num_batches}\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "7d22ddbb-673e-4519-8d85-04d4da45b135",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction of test dataset using re-trained model and save results to csv file\n",
    "# to upload in kaggle\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "class_probs_t1 = []\n",
    "class_preds_t1 = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        x = data\n",
    "        output_t1 = network1(x[0])\n",
    "        \n",
    "        class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "        \n",
    "        _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "\n",
    "        class_probs_t1.append(class_probs_t1_batch)\n",
    "        \n",
    "        class_preds_t1.append(class_preds_t1_batch)\n",
    "        \n",
    "\n",
    "#predictions of D1 test data\n",
    "val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "val_preds_t1 = torch.cat(class_preds_t1).numpy()\n",
    "\n",
    "#write prediction of test data to output for submission to kaggle\n",
    "df_d1_soft_test_preds = df_d1_test_final\n",
    "df_d1_soft_test_preds['target'] = val_preds_t1.tolist()\n",
    "df_d1_soft_test_preds = df_d1_soft_test_preds.drop(['text', 'sentence_embeddings'], axis=1)\n",
    "df_d1_soft_test_preds.to_csv('test_soft_parameter.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2c3069",
   "metadata": {},
   "source": [
    "### The model resulted in Score of 78.51% in Kaggle.(Please refer screenshot in the zip file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5bd89-03bf-48f4-b0ff-db7780713771",
   "metadata": {},
   "source": [
    "## 2. Task Specific Attention based MTL using Hard Parameter Sharing Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bd6e3b-8d43-4a73-9c0b-f9626f560d58",
   "metadata": {},
   "source": [
    "This strategy is an enhancement of the Hard-Parameter sharing MTL model in Section 5. A schematic of the Task Specific attention based MTL is shown in the schematic below"
   ]
  },
  {
   "attachments": {
    "5cad830d-6484-4698-b5c6-e38bed7af6c5.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAu4AAAIKCAYAAAB8yMpeAAAAAXNSR0IArs4c6QAAAIRlWElmTU0A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\n"
    }
   },
   "cell_type": "markdown",
   "id": "38a46edb-5a92-4c2b-ae39-34c0a4eb795e",
   "metadata": {},
   "source": [
    "![attentionMTL.png](attachment:5cad830d-6484-4698-b5c6-e38bed7af6c5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa7eb48-6946-42e9-b658-442ed1b26119",
   "metadata": {},
   "source": [
    "In addition to the hard parameter sharing layers for both tasks, an attention layer that is task specific is implemented after the shared layers. The attention layer is supposed to learn task specific weights during training and apply task specific attention to the two tasks at the output. This means the weights learned will scale the shared features that is coming from the output of the hidden layers according to the task (similar to feature selection from the shared features output that are more important for task specific prediction). This gives some flexibility to learn task specific context in addition to the weights learned in the shared layers for both tasks.\n",
    "\n",
    "Similar to Section 5, the same network architecture is implemented in the shared layers and the only difference is the attention layer with task specific weights (to be learned during training) implemented before the output of each task.For the training, the hyperparameters lambda_1 and lambda_2 of 0.5 is used to test the strategy. The performance results of the model on the validation datset are shown below. It can be seen that there is a slight improvement in the performance compared to just using hard parameter sharing MTL model in Section 5 for the lambda_1 and lambda_2 values of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee11123a-8fe1-4768-b290-b3822e726e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task Specific Attention based MTL model using shared hidden layers\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, input_size, n_tasks):\n",
    "        super().__init__()\n",
    "        self.attention_weights = nn.Parameter(torch.randn(input_size, n_tasks))\n",
    "\n",
    "    def forward(self, x, task):\n",
    "        # Apply attention weights for the specific task\n",
    "        x = x * self.attention_weights[:, task-1]\n",
    "        return x\n",
    "\n",
    "class MultiTaskNeuralNetwork2(nn.Module):\n",
    "    def __init__(self, n_classes_task1, n_classes_task2):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(768, 1024)\n",
    "        self.lin2 = nn.Linear(1024, 512)\n",
    "        self.lin3 = nn.Linear(512, 128)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        # Attention layer\n",
    "        self.attention = AttentionLayer(128, 2)\n",
    "        \n",
    "        # Task-specific output layers\n",
    "        self.out_task1 = nn.Linear(128, n_classes_task1)\n",
    "        self.out_task2 = nn.Linear(128, n_classes_task2)\n",
    "        \n",
    "    def forward(self, x, task):\n",
    "        x = self.lin1(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.lin3(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Apply the attention layer\n",
    "        x = self.attention(x, task)\n",
    "\n",
    "        # Task-specific outputs\n",
    "        if task == 1:\n",
    "            return self.out_task1(x)\n",
    "        if task == 2:\n",
    "            return self.out_task2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c02b5-083b-4189-8993-0dcaece370cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "d3bfa698-54ed-4564-bcd6-ea2ff9913604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5302971888647535\n",
      "Epoch 2, Loss: 0.4337948310891154\n",
      "Epoch 3, Loss: 0.4129075544434419\n",
      "Epoch 4, Loss: 0.4021008241420998\n",
      "Epoch 5, Loss: 0.39512368873746084\n",
      "Epoch 6, Loss: 0.38888380990484583\n",
      "Epoch 7, Loss: 0.3851479219276976\n",
      "Epoch 8, Loss: 0.380165342046351\n",
      "Epoch 9, Loss: 0.37597528052492946\n",
      "Epoch 10, Loss: 0.3724942563402897\n",
      "Epoch 11, Loss: 0.3671983171568373\n",
      "Epoch 12, Loss: 0.36641661425657857\n",
      "Epoch 13, Loss: 0.36098140858300454\n",
      "Epoch 14, Loss: 0.35773462253985483\n",
      "Epoch 15, Loss: 0.3545935908183965\n",
      "Epoch 16, Loss: 0.3485953749448129\n",
      "Epoch 17, Loss: 0.3463942201167413\n",
      "Epoch 18, Loss: 0.34288888300741455\n",
      "Epoch 19, Loss: 0.3383667714435582\n",
      "Epoch 20, Loss: 0.3368120429048777\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "lambda_1 = 0.5\n",
    "lambda_2 = 0.5\n",
    "epochs = 20\n",
    "\n",
    "model2 = MultiTaskNeuralNetwork2(n_classes_task1=2, n_classes_task2=3)\n",
    "\n",
    "# Define separate loss functions for each task\n",
    "criterion_task1 = nn.CrossEntropyLoss()\n",
    "criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for (inputs, labels_task1, labels_task2) in D12_train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        idx1 = labels_task1 != np.nan\n",
    "        idx2 = labels_task2 != np.nan\n",
    "        input1 = inputs[idx1]\n",
    "        input2 = inputs[idx2]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_task1 = model2(input1, task=1)\n",
    "        outputs_task2 = model2(input2, task=2)\n",
    "        \n",
    "        # Compute the losses for each task\n",
    "        loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "        loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "        # Combine the losses with the hyperparameters as factors\n",
    "        loss = lambda_1 * loss_task1 + lambda_2 * loss_task2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(D12_train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "92a27654-9783-40d7-b951-25e112312152",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "truth1 = []\n",
    "truth2 = []\n",
    "class_probs_t1 = []\n",
    "class_probs_t2 = []\n",
    "class_preds_t1 = []\n",
    "class_preds_t2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in D1_hat_val_dataloader:\n",
    "        x, y1, y2 = data\n",
    "        output_t1 = model2(x, task = 1)\n",
    "        output_t2 = model2(x, task = 2)\n",
    "\n",
    "        class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "        class_probs_t2_batch = [nn.Softmax(dim=0)(el) for el in output_t2]\n",
    "        \n",
    "        _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "        _, class_preds_t2_batch = torch.max(output_t2, 1)\n",
    "\n",
    "        class_probs_t1.append(class_probs_t1_batch)\n",
    "        class_probs_t2.append(class_probs_t2_batch)\n",
    "        \n",
    "        class_preds_t1.append(class_preds_t1_batch)\n",
    "        class_preds_t2.append(class_preds_t2_batch)\n",
    "        \n",
    "        truth1.extend([l.item() for l in y1])\n",
    "        truth2.extend([l.item() for l in y2])\n",
    "\n",
    "val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "val_probs_t2 = torch.cat([torch.stack(batch) for batch in class_probs_t2])\n",
    "val_preds_t1 = torch.cat(class_preds_t1)\n",
    "val_preds_t2 = torch.cat(class_preds_t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "a28b7b6a-9d95-41f9-a461-6a78c7b9423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of attention based  based on the first task is 0.7524590163934425\n"
     ]
    }
   ],
   "source": [
    "perf_t1_model2 = f1_score(truth1, val_preds_t1)\n",
    "print(f'The f1 score of attention based  based on the first task is {perf_t1_model2}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011a19a9-7664-4f8c-9d54-2268528dd775",
   "metadata": {},
   "source": [
    "The model is then hyperparameter tuned to assess the best lambda values that give the best performance for our primary task 1. The results of the hyperparamter tuning of the model is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4606a542-28a4-48e4-87df-927382f21c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train and evaluate model for each lambda for attention based MTL model\n",
    "def train_and_evaluate_model_2(lambda_1, lambda_2, train_dataloader, val_dataloader):\n",
    "    \n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "    model2 = MultiTaskNeuralNetwork2(n_classes_task1=2, n_classes_task2=3)\n",
    "\n",
    "    epochs = 20\n",
    "\n",
    "    # Define separate loss functions for each task\n",
    "    criterion_task1 = nn.CrossEntropyLoss()\n",
    "    criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Define the optimizer\n",
    "    optimizer = torch.optim.Adam(model2.parameters(), lr=0.0001)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for (inputs, labels_task1, labels_task2) in train_dataloader:\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            idx1 = labels_task1 != np.nan\n",
    "            idx2 = labels_task2 != np.nan\n",
    "            input1 = inputs[idx1]\n",
    "            input2 = inputs[idx2]\n",
    "\n",
    "            # Forward pass\n",
    "            outputs_task1 = model2(input1, task=1)\n",
    "            outputs_task2 = model2(input2, task=2)\n",
    "\n",
    "            # Compute the losses for each task\n",
    "            loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "            loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "            # Combine the losses with the hyperparameters as factors\n",
    "            loss = lambda_1 * loss_task1 + lambda_2 * loss_task2\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the running loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # # Print the average loss for this epoch\n",
    "        #print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(D12_train_dataloader)}\")\n",
    "\n",
    "    #Evalution of model\n",
    "    torch.manual_seed(rng)\n",
    "    torch.cuda.manual_seed(rng)\n",
    "    torch.cuda.manual_seed_all(rng)\n",
    "    np.random.seed(rng)\n",
    "    random.seed(rng)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    truth1 = []\n",
    "    truth2 = []\n",
    "    class_probs_t1 = []\n",
    "    class_probs_t2 = []\n",
    "    class_preds_t1 = []\n",
    "    class_preds_t2 = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            x, y1, y2 = data\n",
    "            output_t1 = model2(x, task = 1)\n",
    "            output_t2 = model2(x, task = 2)\n",
    "\n",
    "            class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "            class_probs_t2_batch = [nn.Softmax(dim=0)(el) for el in output_t2]\n",
    "\n",
    "            _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "            _, class_preds_t2_batch = torch.max(output_t2, 1)\n",
    "\n",
    "            class_probs_t1.append(class_probs_t1_batch)\n",
    "            class_probs_t2.append(class_probs_t2_batch)\n",
    "\n",
    "            class_preds_t1.append(class_preds_t1_batch)\n",
    "            class_preds_t2.append(class_preds_t2_batch)\n",
    "\n",
    "            truth1.extend([l.item() for l in y1])\n",
    "            truth2.extend([l.item() for l in y2])\n",
    "\n",
    "    val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "    val_probs_t2 = torch.cat([torch.stack(batch) for batch in class_probs_t2])\n",
    "    val_preds_t1 = torch.cat(class_preds_t1)\n",
    "    val_preds_t2 = torch.cat(class_preds_t2)    \n",
    "    \n",
    "    perf_t1_model2 = f1_score(truth1, val_preds_t1)\n",
    "    perf_t2_model2 = accuracy_score(truth2, val_preds_t2)    \n",
    "\n",
    "    return perf_t1_model2, perf_t2_model2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "603ff01b-98f9-48e0-a43b-665a25571e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda_1: 0, Lambda_2: 0, Task 1 Validation f1_score: 0.28349944629014395\n",
      "Lambda_1: 0, Lambda_2: 0.25, Task 1 Validation f1_score: 0.41042893187552565\n",
      "Lambda_1: 0, Lambda_2: 0.5, Task 1 Validation f1_score: 0.47008547008547\n",
      "Lambda_1: 0, Lambda_2: 0.75, Task 1 Validation f1_score: 0.4167350287120591\n",
      "Lambda_1: 0, Lambda_2: 1.0, Task 1 Validation f1_score: 0.4328593996840442\n",
      "Lambda_1: 0.25, Lambda_2: 0, Task 1 Validation f1_score: 0.7510917030567685\n",
      "Lambda_1: 0.25, Lambda_2: 0.25, Task 1 Validation f1_score: 0.7607260726072608\n",
      "Lambda_1: 0.25, Lambda_2: 0.5, Task 1 Validation f1_score: 0.7516556291390728\n",
      "Lambda_1: 0.25, Lambda_2: 0.75, Task 1 Validation f1_score: 0.75\n",
      "Lambda_1: 0.25, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7474916387959866\n",
      "Lambda_1: 0.5, Lambda_2: 0, Task 1 Validation f1_score: 0.7622259696458683\n",
      "Lambda_1: 0.5, Lambda_2: 0.25, Task 1 Validation f1_score: 0.7462932454695222\n",
      "Lambda_1: 0.5, Lambda_2: 0.5, Task 1 Validation f1_score: 0.7524590163934425\n",
      "Lambda_1: 0.5, Lambda_2: 0.75, Task 1 Validation f1_score: 0.7539353769676884\n",
      "Lambda_1: 0.5, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7516556291390728\n",
      "Lambda_1: 0.75, Lambda_2: 0, Task 1 Validation f1_score: 0.7597292724196278\n",
      "Lambda_1: 0.75, Lambda_2: 0.25, Task 1 Validation f1_score: 0.7489361702127659\n",
      "Lambda_1: 0.75, Lambda_2: 0.5, Task 1 Validation f1_score: 0.7529976019184652\n",
      "Lambda_1: 0.75, Lambda_2: 0.75, Task 1 Validation f1_score: 0.7475409836065573\n",
      "Lambda_1: 0.75, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7469287469287469\n",
      "Lambda_1: 1.0, Lambda_2: 0, Task 1 Validation f1_score: 0.7551369863013698\n",
      "Lambda_1: 1.0, Lambda_2: 0.25, Task 1 Validation f1_score: 0.757071547420965\n",
      "Lambda_1: 1.0, Lambda_2: 0.5, Task 1 Validation f1_score: 0.7547169811320754\n",
      "Lambda_1: 1.0, Lambda_2: 0.75, Task 1 Validation f1_score: 0.7554076539101497\n",
      "Lambda_1: 1.0, Lambda_2: 1.0, Task 1 Validation f1_score: 0.7529021558872305\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch to find optimal lambda for obtaining best task 1 performance on \n",
    "# attention based MTL model\n",
    "lambda_1_list = [0, 0.25, 0.5, 0.75, 1.0] \n",
    "lambda_2_list = [0, 0.25, 0.5, 0.75, 1.0]\n",
    "best_lambda_1 = None\n",
    "best_lambda_2 = None\n",
    "best_t1_val_perf = 0\n",
    "\n",
    "## Run all combinations of lambda1 and lambda2 to find best combination for best \n",
    "## T1 performance\n",
    "for lambda_1 in lambda_1_list:\n",
    "\n",
    "    for lambda_2 in lambda_2_list:\n",
    "        \n",
    "        task1_val_perf, task2_val_perf = train_and_evaluate_model_2(lambda_1, lambda_2, D12_train_dataloader, D1_hat_val_dataloader)\n",
    "        \n",
    "        print(f\"Lambda_1: {lambda_1}, Lambda_2: {lambda_2}, Task 1 Validation f1_score: {task1_val_perf}\")\n",
    "        \n",
    "        if task1_val_perf > best_t1_val_perf:\n",
    "            best_t1_val_perf = task1_val_perf\n",
    "            best_lambda_1 = lambda_1\n",
    "            best_lambda_2 = lambda_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc39f2ff-1d26-4a75-8694-6ecde3b4abb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best lambda_1 value is: 0.5\n",
      "The best lambda_2 value is: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The best lambda_1 value is: {best_lambda_1}\")\n",
    "print(f\"The best lambda_2 value is: {best_lambda_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09eeb2-1556-4ec5-b65d-925501eeeaec",
   "metadata": {},
   "source": [
    "The best hyperparameters for lambda_1 and lambda_2 are 0.5 and 0 respectively which gives the best performance for task 1 on the validation dataset. The performance of the model is also better for task 1 compared to the model trained only on D1 dataset in Section 1. The performance of the model is also better than the hyperparameter tuned hard parameter sharing model detailed in Section 6.\n",
    "\n",
    "As discussed in Section 8, lambda2 = 0 (loss function is only based on task 1 loss) in this MTL model gives the best performance for predicting task 1 as all the attention is given to task 1 when training the model.\n",
    "\n",
    "These optimised lambdas were used to re-train the MTL model. The re-trained optimised for task 1 model is then used to predict the labels for the D1 test dataset to be submitted in Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "175fa89e-6469-4645-be34-669ae1eacb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.08695137546162263\n",
      "Epoch 2, Loss: 0.061206184484590705\n",
      "Epoch 3, Loss: 0.058621256803173004\n",
      "Epoch 4, Loss: 0.05705142860112029\n",
      "Epoch 5, Loss: 0.05526326881013047\n",
      "Epoch 6, Loss: 0.05389934435384963\n",
      "Epoch 7, Loss: 0.05316305579935839\n",
      "Epoch 8, Loss: 0.0522527131591425\n",
      "Epoch 9, Loss: 0.05122248517192374\n",
      "Epoch 10, Loss: 0.050608612104809096\n",
      "Epoch 11, Loss: 0.049534805750570864\n",
      "Epoch 12, Loss: 0.04931032584220646\n",
      "Epoch 13, Loss: 0.04798620392447486\n",
      "Epoch 14, Loss: 0.04662113573512482\n",
      "Epoch 15, Loss: 0.046010353493213585\n",
      "Epoch 16, Loss: 0.04476061545615774\n",
      "Epoch 17, Loss: 0.04419420524616991\n",
      "Epoch 18, Loss: 0.04273271106463562\n",
      "Epoch 19, Loss: 0.041674643961801816\n",
      "Epoch 20, Loss: 0.04114870229844165\n"
     ]
    }
   ],
   "source": [
    "# Final attention based MTL model with lambda1= 0.5 and lambda2= 0\n",
    "\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "lambda_1 = 0.5\n",
    "lambda_2 = 0\n",
    "epochs = 20\n",
    "\n",
    "model2 = MultiTaskNeuralNetwork2(n_classes_task1=2, n_classes_task2=3)\n",
    "\n",
    "# Define separate loss functions for each task\n",
    "criterion_task1 = nn.CrossEntropyLoss()\n",
    "criterion_task2 = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for (inputs, labels_task1, labels_task2) in D12_train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        idx1 = labels_task1 != np.nan\n",
    "        idx2 = labels_task2 != np.nan\n",
    "        input1 = inputs[idx1]\n",
    "        input2 = inputs[idx2]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_task1 = model2(input1, task=1)\n",
    "        outputs_task2 = model2(input2, task=2)\n",
    "\n",
    "        # Compute the losses for each task\n",
    "        loss_task1 = criterion_task1(outputs_task1, (labels_task1[idx1]).type(torch.LongTensor))\n",
    "        loss_task2 = criterion_task2(outputs_task2, (labels_task2[idx2]).type(torch.LongTensor))\n",
    "\n",
    "        # Combine the losses with the hyperparameters as factors\n",
    "        loss = lambda_1 * loss_task1 + lambda_2 * loss_task2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the average loss for this epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(D12_train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc94c5a-fb7c-4f1e-abe2-45adaaaf0378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction of test dataset using re-trained model and save results to csv file\n",
    "# to upload in kaggle\n",
    "\n",
    "torch.manual_seed(rng)\n",
    "torch.cuda.manual_seed(rng)\n",
    "torch.cuda.manual_seed_all(rng)\n",
    "np.random.seed(rng)\n",
    "random.seed(rng)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "class_probs_t1 = []\n",
    "class_preds_t1 = []\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        x = data\n",
    "        output_t1 = model2(x[0], task = 1)\n",
    "\n",
    "        class_probs_t1_batch = [nn.Softmax(dim=0)(el) for el in output_t1]\n",
    "\n",
    "        _, class_preds_t1_batch = torch.max(output_t1, 1)\n",
    "\n",
    "        class_probs_t1.append(class_probs_t1_batch)\n",
    "        \n",
    "        class_preds_t1.append(class_preds_t1_batch)\n",
    "\n",
    "\n",
    "#predictions of D1 test data\n",
    "val_probs_t1 = torch.cat([torch.stack(batch) for batch in class_probs_t1])\n",
    "val_preds_t1 = torch.cat(class_preds_t1).numpy()\n",
    "\n",
    "#write prediction of test data to output for submission to kaggle\n",
    "df_d1_atten_test_preds = df_d1_test_final\n",
    "df_d1_atten_test_preds['target'] = val_preds_t1.tolist()\n",
    "df_d1_atten_test_preds = df_d1_atten_test_preds.drop(['text', 'sentence_embeddings'], axis=1)\n",
    "df_d1_atten_test_preds.to_csv('test_atten_parameter.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad908a29",
   "metadata": {},
   "source": [
    "### The model resulted in Score of 80.04% in Kaggle.(Please refer screenshot in the zip file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44599af9-874b-4e77-a425-132918c1c4e1",
   "metadata": {},
   "source": [
    "Since we have the attention based layer to scale the shared features according to the task, it can be argued that hyper parameters may not be needed. This can be tested by observing the performance of the model for lambda1 = 1 and lambda2 = 1. The f1 score for task 1 on the validation data is about 0.752 (results of the gridsearch). However, by hyperparameter tuning, we can get better results with lambda1=0.5 and lambda2=0 with a f1 score of 0.7622. Therefore, even though we have the attention layer to help the model learn task specific features, the hyper parameters further improve in improving the performance of primary task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80691d0-4fb4-4907-b66f-13d002c53158",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
